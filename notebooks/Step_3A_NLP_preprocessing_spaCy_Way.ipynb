{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b28363",
   "metadata": {},
   "source": [
    "This 3A notebook will be perform the second half of NLP preprocessing using spaCy, mostly.  Also, this will produce a large dataframe two lyric sets (with/with out stopwords), each with word counts and spaCy .doc (vectorization, POS tags, Named Entity recognition, etc.).\n",
    "\n",
    "[NEED TO RUN AFFINITY (AFINN) TO MARRY UP WITH NB 3.]\n",
    "\n",
    "Pull down the dataset which completed some, but not all of the NLP preprocessing in NB 3 (Using the Fake News group's pre-processing as a guide (https://github.com/georgetown-analytics/From-Russia-With-Love-fake-news-/blob/master/Notebooks/Step_1_Data_Cleaning.ipynb)). \n",
    "\n",
    "This particular set has been through: lowercase, remove URLs, ww, special characters, extra whitespace, accented characters and expanded contractions.\n",
    "\n",
    "Will run spaCy and word counts as is.  Then will remove stopwords. Then rerun spaCy pipeline and count the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770348ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-4fce9e1e4886>:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100000)\n",
    "pd.set_option('display.max_row', 1000000)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "# import tldextract \"\"\"Accurately separate the TLD from the registered domain and subdomains of a URL\"\"\"\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\", leave=False)\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from spacy.lang import punctuation\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import unicodedata  # might need to pip install unicodedate2 on aws sagemaker\n",
    "import contractions\n",
    "from contractions import contractions_dict ## pip installed this\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import warnings\n",
    "from afinn import Afinn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2',rc={'figure.figsize':(9,6),'figure.dpi':90})\n",
    "\n",
    "punctuation = string.punctuation + '”' + '“' + '–' + '““' + \"’’\" + '”'\n",
    "stopword = stopwords.words('english')\n",
    "stopwords = set(STOPWORDS)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6b61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=False,key='###',secret='###')\n",
    "\n",
    "g_df = pd.read_csv('s3://music-lyrics-chain/genres_midcln_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173300e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86391 entries, 0 to 86390\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   original_csv  86391 non-null  object \n",
      " 1   artist_name   86391 non-null  object \n",
      " 2   song_name     86391 non-null  object \n",
      " 3   link          86391 non-null  object \n",
      " 4   lyrics        86391 non-null  object \n",
      " 5   language      86391 non-null  object \n",
      " 6   genre         86391 non-null  object \n",
      " 7   date          0 non-null      float64\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df068b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86391, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e014c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i used to think one day we would tell the story of us. how we met and sparks flew instantly. people would say they are the lucky ones. i used to know my place was a spot next to you. now I am searching the room for an empty seat. because lately i do not even know what page you are on. oh. a simple complication, miscommunication. has lead to fallout. too many things that i wish you knew. so many walls up i can not break through. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. next chapter. how did we end up this way?. se me nervously pulling at my clothes. and trying to look busy. and you are doing your best to avoid me. I am starting to think one day I will tell the story of us. how i was losing my mind when i saw you here. but you held your pride like you should have held me. oh. I am scared to see the ending. why are we pretending this is nothing?. I would tell you i miss you but i do not know how. I have never heard silence quite this loud. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. this is looking like a contest. of who can act like they care less. but i liked it better when you were on my side. the battles in your hands now. but i will lay my armor down. if you say you would rather love than fight. so many things that you wish i knew. but the story of us might be ending soon. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. but i do not know what to say. since the twist of fate. and it all broke down. and the story of us looks a lot like a tragedy now. now, now. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. i do not know what to say. since the twist of fate. because we are going down. and the story of us looks a lot like a tragedy now. the end'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d738fa30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (188) does not match length of index (86391)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-620e843b7f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnew_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mg_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spaCy_Doc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3242\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \"\"\"\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (188) does not match length of index (86391)"
     ]
    }
   ],
   "source": [
    "lyrics = [_ for _ in g_df['lyrics']]\n",
    "\n",
    "#def set_doc(lyrics):\n",
    "    #scores = []\n",
    "    #for t in lyrics:\n",
    "        #doc = nlp(t)\n",
    "        #scores.append(doc)\n",
    "    #return scores\n",
    "\n",
    "new_doc = list(nlp.pipe(lyrics))[0]\n",
    "\n",
    "g_df['spaCy_Doc'] = new_doc\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54838e4d",
   "metadata": {},
   "source": [
    "nlp.pipe(text) didn't work - didn't match the amount of inputs?  Hmmm.  Sure this is more a python problem on my end vice a problem in spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857da8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "lyrics = [_ for _ in g_df['lyrics']]\n",
    "\n",
    "def set_doc(lyrics):\n",
    "    scores = []\n",
    "    for t in lyrics:\n",
    "        doc = nlp(t)\n",
    "        scores.append(doc)\n",
    "    return scores\n",
    "\n",
    "new_doc = set_doc(g_df['lyrics'].tolist())\n",
    "\n",
    "g_df['spaCy_Doc'] = new_doc\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb19ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86391, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cf74c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>spaCy_Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>i could feel at the time. there was no way of ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(i, could, feel, at, the, time, ., there, was,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>take me now, baby, here as i am. hold me close...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(take, me, now, ,, baby, ,, here, as, i, am, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>these are. these are days you will remember. n...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(these, are, ., these, are, days, you, will, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>a lie to say, \"of my mountain has coal veins a...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a, lie, to, say, ,, \", of, my, mountain, has,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly over wet sand. back to the ben...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(trudging, slowly, over, wet, sand, ., back, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  i could feel at the time. there was no way of ...  ENGLISH  Rock   NaN   \n",
       "1  take me now, baby, here as i am. hold me close...  ENGLISH  Rock   NaN   \n",
       "2  these are. these are days you will remember. n...  ENGLISH  Rock   NaN   \n",
       "3  a lie to say, \"of my mountain has coal veins a...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly over wet sand. back to the ben...  ENGLISH  Rock   NaN   \n",
       "\n",
       "                                           spaCy_Doc  \n",
       "0  (i, could, feel, at, the, time, ., there, was,...  \n",
       "1  (take, me, now, ,, baby, ,, here, as, i, am, ....  \n",
       "2  (these, are, ., these, are, days, you, will, r...  \n",
       "3  (a, lie, to, say, ,, \", of, my, mountain, has,...  \n",
       "4  (trudging, slowly, over, wet, sand, ., back, t...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd6be914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i used to think one day we would tell the story of us. how we met and sparks flew instantly. people would say they are the lucky ones. i used to know my place was a spot next to you. now I am searching the room for an empty seat. because lately i do not even know what page you are on. oh. a simple complication, miscommunication. has lead to fallout. too many things that i wish you knew. so many walls up i can not break through. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. next chapter. how did we end up this way?. se me nervously pulling at my clothes. and trying to look busy. and you are doing your best to avoid me. I am starting to think one day I will tell the story of us. how i was losing my mind when i saw you here. but you held your pride like you should have held me. oh. I am scared to see the ending. why are we pretending this is nothing?. I would tell you i miss you but i do not know how. I have never heard silence quite this loud. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. this is looking like a contest. of who can act like they care less. but i liked it better when you were on my side. the battles in your hands now. but i will lay my armor down. if you say you would rather love than fight. so many things that you wish i knew. but the story of us might be ending soon. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. but i do not know what to say. since the twist of fate. and it all broke down. and the story of us looks a lot like a tragedy now. now, now. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. i do not know what to say. since the twist of fate. because we are going down. and the story of us looks a lot like a tragedy now. the end"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[84304]['spaCy_Doc']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d7e2bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./g_spaCy1_df.csv to s3://music-lyrics-chain/g_spaCy1_df.csv\n",
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "!touch g_spaCy1_df.csv\n",
    "g_df.to_csv('g_spaCy1_df.csv', index= False)\n",
    "!aws s3 cp g_spaCy1_df.csv s3://music-lyrics-chain/g_spaCy1_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18314523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 80.6 ms, total: 3.31 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word counts\n",
    "g_df['word_count'] = g_df[\"lyrics\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "g_df['character_count'] = g_df[\"lyrics\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "g_df['avg_word_length'] = g_df['character_count'] / g_df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d27c0033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>spaCy_Doc</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>i could feel at the time. there was no way of ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(i, could, feel, at, the, time, ., there, was,...</td>\n",
       "      <td>154</td>\n",
       "      <td>611</td>\n",
       "      <td>3.967532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>take me now, baby, here as i am. hold me close...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(take, me, now, ,, baby, ,, here, as, i, am, ....</td>\n",
       "      <td>246</td>\n",
       "      <td>1023</td>\n",
       "      <td>4.158537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>these are. these are days you will remember. n...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(these, are, ., these, are, days, you, will, r...</td>\n",
       "      <td>181</td>\n",
       "      <td>717</td>\n",
       "      <td>3.961326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>a lie to say, \"of my mountain has coal veins a...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a, lie, to, say, ,, \", of, my, mountain, has,...</td>\n",
       "      <td>272</td>\n",
       "      <td>1027</td>\n",
       "      <td>3.775735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly over wet sand. back to the ben...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(trudging, slowly, over, wet, sand, ., back, t...</td>\n",
       "      <td>117</td>\n",
       "      <td>530</td>\n",
       "      <td>4.529915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  i could feel at the time. there was no way of ...  ENGLISH  Rock   NaN   \n",
       "1  take me now, baby, here as i am. hold me close...  ENGLISH  Rock   NaN   \n",
       "2  these are. these are days you will remember. n...  ENGLISH  Rock   NaN   \n",
       "3  a lie to say, \"of my mountain has coal veins a...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly over wet sand. back to the ben...  ENGLISH  Rock   NaN   \n",
       "\n",
       "                                           spaCy_Doc  word_count  \\\n",
       "0  (i, could, feel, at, the, time, ., there, was,...         154   \n",
       "1  (take, me, now, ,, baby, ,, here, as, i, am, ....         246   \n",
       "2  (these, are, ., these, are, days, you, will, r...         181   \n",
       "3  (a, lie, to, say, ,, \", of, my, mountain, has,...         272   \n",
       "4  (trudging, slowly, over, wet, sand, ., back, t...         117   \n",
       "\n",
       "   character_count  avg_word_length  \n",
       "0              611         3.967532  \n",
       "1             1023         4.158537  \n",
       "2              717         3.961326  \n",
       "3             1027         3.775735  \n",
       "4              530         4.529915  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0f3f3",
   "metadata": {},
   "source": [
    "Creating the _sml version of the lyrics, the spaCy_Doc column and the word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34fdd742",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "def replace_punctuation(text):\n",
    "    filters = string.punctuation + '”' + '“' + '–' \n",
    "    translate_dict = dict((c, \" \") for c in filters)   \n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    return text\n",
    "\n",
    "def stops_letters(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stopword:\n",
    "            result.append(token)\n",
    "            \n",
    "    return \" \".join(result)\n",
    "\n",
    "g_df['lyrics_sml'] =g_df['lyrics'].apply(replace_punctuation)\n",
    "g_df['lyrics_sml'] =g_df['lyrics'].apply(stops_letters)\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca72336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>spaCy_Doc</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lyrics_sml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>i could feel at the time. there was no way of ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(i, could, feel, at, the, time, ., there, was,...</td>\n",
       "      <td>154</td>\n",
       "      <td>611</td>\n",
       "      <td>3.967532</td>\n",
       "      <td>feel time way knowing fallen leaves night blow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>take me now, baby, here as i am. hold me close...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(take, me, now, ,, baby, ,, here, as, i, am, ....</td>\n",
       "      <td>246</td>\n",
       "      <td>1023</td>\n",
       "      <td>4.158537</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>these are. these are days you will remember. n...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(these, are, ., these, are, days, you, will, r...</td>\n",
       "      <td>181</td>\n",
       "      <td>717</td>\n",
       "      <td>3.961326</td>\n",
       "      <td>days remember promise world warm feel know tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>a lie to say, \"of my mountain has coal veins a...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a, lie, to, say, ,, \", of, my, mountain, has,...</td>\n",
       "      <td>272</td>\n",
       "      <td>1027</td>\n",
       "      <td>3.775735</td>\n",
       "      <td>lie mountain coal veins beds dig men axes dig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly over wet sand. back to the ben...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(trudging, slowly, over, wet, sand, ., back, t...</td>\n",
       "      <td>117</td>\n",
       "      <td>530</td>\n",
       "      <td>4.529915</td>\n",
       "      <td>trudging slowly wet sand bench clothes stolen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  i could feel at the time. there was no way of ...  ENGLISH  Rock   NaN   \n",
       "1  take me now, baby, here as i am. hold me close...  ENGLISH  Rock   NaN   \n",
       "2  these are. these are days you will remember. n...  ENGLISH  Rock   NaN   \n",
       "3  a lie to say, \"of my mountain has coal veins a...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly over wet sand. back to the ben...  ENGLISH  Rock   NaN   \n",
       "\n",
       "                                           spaCy_Doc  word_count  \\\n",
       "0  (i, could, feel, at, the, time, ., there, was,...         154   \n",
       "1  (take, me, now, ,, baby, ,, here, as, i, am, ....         246   \n",
       "2  (these, are, ., these, are, days, you, will, r...         181   \n",
       "3  (a, lie, to, say, ,, \", of, my, mountain, has,...         272   \n",
       "4  (trudging, slowly, over, wet, sand, ., back, t...         117   \n",
       "\n",
       "   character_count  avg_word_length  \\\n",
       "0              611         3.967532   \n",
       "1             1023         4.158537   \n",
       "2              717         3.961326   \n",
       "3             1027         3.775735   \n",
       "4              530         4.529915   \n",
       "\n",
       "                                          lyrics_sml  \n",
       "0  feel time way knowing fallen leaves night blow...  \n",
       "1  baby hold close try understand desire hunger b...  \n",
       "2  days remember promise world warm feel know tru...  \n",
       "3  lie mountain coal veins beds dig men axes dig ...  \n",
       "4  trudging slowly wet sand bench clothes stolen ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba4e4a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think day tell story met sparks flew instantly people lucky ones know place spot searching room seat lately know page simple complication lead fallout things wish knew walls break standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy chapter end way nervously pulling clothes trying look busy best avoid starting think day tell story losing mind saw held pride like held scared ending pretending tell miss know heard silence loud standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy looking like contest act like care liked better battles hands lay armor love fight things wish knew story ending soon standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy speaking dying know killing like killing know twist fate going story looks lot like tragedy end'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[84304]['lyrics_sml']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c14fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "lyrics = [_ for _ in g_df['lyrics_sml']]\n",
    "\n",
    "def set_doc(lyrics):\n",
    "    scores = []\n",
    "    for t in lyrics:\n",
    "        doc = nlp(t)\n",
    "        scores.append(doc)\n",
    "    return scores\n",
    "\n",
    "new_doc = set_doc(g_df['lyrics'].tolist())\n",
    "\n",
    "g_df['spaCy_Doc_sml'] = new_doc\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e4f4beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>spaCy_Doc</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lyrics_sml</th>\n",
       "      <th>spaCy_Doc_sml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>i could feel at the time. there was no way of ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(i, could, feel, at, the, time, ., there, was,...</td>\n",
       "      <td>154</td>\n",
       "      <td>611</td>\n",
       "      <td>3.967532</td>\n",
       "      <td>feel time way knowing fallen leaves night blow...</td>\n",
       "      <td>(i, could, feel, at, the, time, ., there, was,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>take me now, baby, here as i am. hold me close...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(take, me, now, ,, baby, ,, here, as, i, am, ....</td>\n",
       "      <td>246</td>\n",
       "      <td>1023</td>\n",
       "      <td>4.158537</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "      <td>(take, me, now, ,, baby, ,, here, as, i, am, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>these are. these are days you will remember. n...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(these, are, ., these, are, days, you, will, r...</td>\n",
       "      <td>181</td>\n",
       "      <td>717</td>\n",
       "      <td>3.961326</td>\n",
       "      <td>days remember promise world warm feel know tru...</td>\n",
       "      <td>(these, are, ., these, are, days, you, will, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>a lie to say, \"of my mountain has coal veins a...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a, lie, to, say, ,, \", of, my, mountain, has,...</td>\n",
       "      <td>272</td>\n",
       "      <td>1027</td>\n",
       "      <td>3.775735</td>\n",
       "      <td>lie mountain coal veins beds dig men axes dig ...</td>\n",
       "      <td>(a, lie, to, say, ,, \", of, my, mountain, has,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly over wet sand. back to the ben...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(trudging, slowly, over, wet, sand, ., back, t...</td>\n",
       "      <td>117</td>\n",
       "      <td>530</td>\n",
       "      <td>4.529915</td>\n",
       "      <td>trudging slowly wet sand bench clothes stolen ...</td>\n",
       "      <td>(trudging, slowly, over, wet, sand, ., back, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  i could feel at the time. there was no way of ...  ENGLISH  Rock   NaN   \n",
       "1  take me now, baby, here as i am. hold me close...  ENGLISH  Rock   NaN   \n",
       "2  these are. these are days you will remember. n...  ENGLISH  Rock   NaN   \n",
       "3  a lie to say, \"of my mountain has coal veins a...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly over wet sand. back to the ben...  ENGLISH  Rock   NaN   \n",
       "\n",
       "                                           spaCy_Doc  word_count  \\\n",
       "0  (i, could, feel, at, the, time, ., there, was,...         154   \n",
       "1  (take, me, now, ,, baby, ,, here, as, i, am, ....         246   \n",
       "2  (these, are, ., these, are, days, you, will, r...         181   \n",
       "3  (a, lie, to, say, ,, \", of, my, mountain, has,...         272   \n",
       "4  (trudging, slowly, over, wet, sand, ., back, t...         117   \n",
       "\n",
       "   character_count  avg_word_length  \\\n",
       "0              611         3.967532   \n",
       "1             1023         4.158537   \n",
       "2              717         3.961326   \n",
       "3             1027         3.775735   \n",
       "4              530         4.529915   \n",
       "\n",
       "                                          lyrics_sml  \\\n",
       "0  feel time way knowing fallen leaves night blow...   \n",
       "1  baby hold close try understand desire hunger b...   \n",
       "2  days remember promise world warm feel know tru...   \n",
       "3  lie mountain coal veins beds dig men axes dig ...   \n",
       "4  trudging slowly wet sand bench clothes stolen ...   \n",
       "\n",
       "                                       spaCy_Doc_sml  \n",
       "0  (i, could, feel, at, the, time, ., there, was,...  \n",
       "1  (take, me, now, ,, baby, ,, here, as, i, am, ....  \n",
       "2  (these, are, ., these, are, days, you, will, r...  \n",
       "3  (a, lie, to, say, ,, \", of, my, mountain, has,...  \n",
       "4  (trudging, slowly, over, wet, sand, ., back, t...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bef4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 38.2 ms, total: 1.32 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word counts\n",
    "g_df['word_count_sml'] = g_df['lyrics_sml'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "g_df['character_count_sml'] = g_df['lyrics_sml'].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "g_df['avg_word_length_sml'] = g_df['character_count_sml'] / g_df['word_count_sml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3841b0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>spaCy_Doc</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lyrics_sml</th>\n",
       "      <th>spaCy_Doc_sml</th>\n",
       "      <th>word_count_sml</th>\n",
       "      <th>character_count_sml</th>\n",
       "      <th>avg_word_length_sml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391.000000</td>\n",
       "      <td>86391.000000</td>\n",
       "      <td>86391.000000</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391.000000</td>\n",
       "      <td>86391.000000</td>\n",
       "      <td>86391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1147</td>\n",
       "      <td>66856</td>\n",
       "      <td>86391</td>\n",
       "      <td>86309</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85463</td>\n",
       "      <td>86391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>elvis-presley</td>\n",
       "      <td>Intro</td>\n",
       "      <td>/eric-clapton/better-make-it-through-today.html</td>\n",
       "      <td>so, so you think you can tell. heaven from hel...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(it, is, been, a, long, ,, long, while, ., sin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merry little christmas let heart light trouble...</td>\n",
       "      <td>(whoow, !, here, is, a, little, song, for, eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>86391</td>\n",
       "      <td>747</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>86391</td>\n",
       "      <td>47408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.744059</td>\n",
       "      <td>1132.871051</td>\n",
       "      <td>3.942745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.420032</td>\n",
       "      <td>552.281418</td>\n",
       "      <td>5.120008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.241573</td>\n",
       "      <td>691.961143</td>\n",
       "      <td>0.376259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.626140</td>\n",
       "      <td>379.383164</td>\n",
       "      <td>0.468566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.740741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>3.719021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>4.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>3.903427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>5.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>4.116123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>5.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425.000000</td>\n",
       "      <td>14705.000000</td>\n",
       "      <td>35.145455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>7212.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_csv    artist_name song_name  \\\n",
       "count         86391          86391     86391   \n",
       "unique            1           1147     66856   \n",
       "top      genres_csv  elvis-presley     Intro   \n",
       "freq          86391            747        50   \n",
       "mean            NaN            NaN       NaN   \n",
       "std             NaN            NaN       NaN   \n",
       "min             NaN            NaN       NaN   \n",
       "25%             NaN            NaN       NaN   \n",
       "50%             NaN            NaN       NaN   \n",
       "75%             NaN            NaN       NaN   \n",
       "max             NaN            NaN       NaN   \n",
       "\n",
       "                                                   link  \\\n",
       "count                                             86391   \n",
       "unique                                            86391   \n",
       "top     /eric-clapton/better-make-it-through-today.html   \n",
       "freq                                                  1   \n",
       "mean                                                NaN   \n",
       "std                                                 NaN   \n",
       "min                                                 NaN   \n",
       "25%                                                 NaN   \n",
       "50%                                                 NaN   \n",
       "75%                                                 NaN   \n",
       "max                                                 NaN   \n",
       "\n",
       "                                                   lyrics language  genre  \\\n",
       "count                                               86391    86391  86391   \n",
       "unique                                              86309        1      6   \n",
       "top     so, so you think you can tell. heaven from hel...  ENGLISH   Rock   \n",
       "freq                                                    3    86391  47408   \n",
       "mean                                                  NaN      NaN    NaN   \n",
       "std                                                   NaN      NaN    NaN   \n",
       "min                                                   NaN      NaN    NaN   \n",
       "25%                                                   NaN      NaN    NaN   \n",
       "50%                                                   NaN      NaN    NaN   \n",
       "75%                                                   NaN      NaN    NaN   \n",
       "max                                                   NaN      NaN    NaN   \n",
       "\n",
       "        date                                          spaCy_Doc    word_count  \\\n",
       "count    0.0                                              86391  86391.000000   \n",
       "unique   NaN                                              86391           NaN   \n",
       "top      NaN  (it, is, been, a, long, ,, long, while, ., sin...           NaN   \n",
       "freq     NaN                                                  1           NaN   \n",
       "mean     NaN                                                NaN    289.744059   \n",
       "std      NaN                                                NaN    177.241573   \n",
       "min      NaN                                                NaN      1.000000   \n",
       "25%      NaN                                                NaN    171.000000   \n",
       "50%      NaN                                                NaN    245.000000   \n",
       "75%      NaN                                                NaN    357.000000   \n",
       "max      NaN                                                NaN   3425.000000   \n",
       "\n",
       "        character_count  avg_word_length  \\\n",
       "count      86391.000000     86391.000000   \n",
       "unique              NaN              NaN   \n",
       "top                 NaN              NaN   \n",
       "freq                NaN              NaN   \n",
       "mean        1132.871051         3.942745   \n",
       "std          691.961143         0.376259   \n",
       "min            8.000000         1.740741   \n",
       "25%          677.000000         3.719021   \n",
       "50%          961.000000         3.903427   \n",
       "75%         1381.000000         4.116123   \n",
       "max        14705.000000        35.145455   \n",
       "\n",
       "                                               lyrics_sml  \\\n",
       "count                                               86391   \n",
       "unique                                              85463   \n",
       "top     merry little christmas let heart light trouble...   \n",
       "freq                                                    4   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            spaCy_Doc_sml  word_count_sml  \\\n",
       "count                                               86391    86391.000000   \n",
       "unique                                              86391             NaN   \n",
       "top     (whoow, !, here, is, a, little, song, for, eve...             NaN   \n",
       "freq                                                    1             NaN   \n",
       "mean                                                  NaN      108.420032   \n",
       "std                                                   NaN       74.626140   \n",
       "min                                                   NaN        1.000000   \n",
       "25%                                                   NaN       61.000000   \n",
       "50%                                                   NaN       88.000000   \n",
       "75%                                                   NaN      129.000000   \n",
       "max                                                   NaN     1380.000000   \n",
       "\n",
       "        character_count_sml  avg_word_length_sml  \n",
       "count          86391.000000         86391.000000  \n",
       "unique                  NaN                  NaN  \n",
       "top                     NaN                  NaN  \n",
       "freq                    NaN                  NaN  \n",
       "mean             552.281418             5.120008  \n",
       "std              379.383164             0.468566  \n",
       "min                0.000000             0.000000  \n",
       "25%              312.000000             4.812500  \n",
       "50%              450.000000             5.083333  \n",
       "75%              661.000000             5.384615  \n",
       "max             7212.000000            12.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7207474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./g_spaCy2_df.csv to s3://music-lyrics-chain/g_spaCy2_df.csv\n",
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "!touch g_spaCy2_df.csv\n",
    "g_df.to_csv('g_spaCy2_df.csv', index= False)\n",
    "!aws s3 cp g_spaCy2_df.csv s3://music-lyrics-chain/g_spaCy2_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "291591a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_csv                                                  genres_csv\n",
       "artist_name                                                 taylor-swift\n",
       "song_name                                                The Story Of Us\n",
       "link                                  /taylor-swift/the-story-of-us.html\n",
       "lyrics                 i used to think one day we would tell the stor...\n",
       "language                                                         ENGLISH\n",
       "genre                                                                Pop\n",
       "date                                                                 NaN\n",
       "spaCy_Doc              (i, used, to, think, one, day, we, would, tell...\n",
       "word_count                                                           484\n",
       "character_count                                                     1764\n",
       "avg_word_length                                                 3.644628\n",
       "lyrics_sml             think day tell story met sparks flew instantly...\n",
       "spaCy_Doc_sml          (i, used, to, think, one, day, we, would, tell...\n",
       "word_count_sml                                                       151\n",
       "character_count_sml                                                  781\n",
       "avg_word_length_sml                                             5.172185\n",
       "Name: 84304, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.loc[84304]#genres Taylor Swift The Story of Us"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
