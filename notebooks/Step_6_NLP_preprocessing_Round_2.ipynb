{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7915a7f",
   "metadata": {},
   "source": [
    "This notebook will perform some amount of wrangling, repeat all previous Natural Language Processing (NLP) preprocessing, and conduct feature engineering.  The feature engineering leverages work conducted in Step_5_Create_Stop_and_Unique_words and will be used to domain-specifc scoring (like sentiment) and expanded, domain-specific stopwords list.\n",
    "\n",
    "This notebook will have a companion python script in the 'sample' folder of this Git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8a299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-7cb64389c0eb>:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\", leave=False)\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from spacy.lang import punctuation\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import unicodedata  # might need to pip install unicodedate2 on aws sagemaker\n",
    "import contractions\n",
    "from contractions import contractions_dict ## pip installed this\n",
    "from wordcloud import WordCloud, STOPWORDS #pip install\n",
    "from textblob import TextBlob\n",
    "!python -m textblob.download_corpora\n",
    "from afinn import Afinn\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "cores = mp.cpu_count()\n",
    "\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2',rc={'figure.figsize':(9,6),'figure.dpi':90})\n",
    "\n",
    "punctuation = string.punctuation + '”' + '“' + '–' + '““' + \"’’\" + '”'\n",
    "stopword = stopwords.words('english')\n",
    "stopwords = set(STOPWORDS)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Increase screen size.\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 100000)\n",
    "pd.set_option('display.max_columns', 100000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2', rc={'figure.figsize':(9,6), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ee6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Admin Issues\n",
    "\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "def aws_session(region_name='us-east-1'):\n",
    "    return boto3.session.Session(aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'), #looks for any .env file\n",
    "                                aws_secret_access_key=os.getenv('AWS_ACCESS_KEY_SECRET'), #Has to be in same directory\n",
    "                                region_name=region_name) #from above\n",
    "\n",
    "def make_bucket(name, acl): \n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    return s3_resource.create_bucket(Bucket=name, ACL=acl)\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, file_path):\n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    file_dir, file_name = os.path.split(file_path)\n",
    "\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    bucket.upload_file(\n",
    "      Filename=file_path,\n",
    "      Key=file_name,\n",
    "      ExtraArgs={'ACL': 'public-read'}\n",
    "    )\n",
    "\n",
    "    s3_url = f\"https://{bucket_name}.s3.amazonaws.com/{file_name}\"\n",
    "    return s3_url\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False,key='####',secret='####'')\n",
    "\n",
    "#g_df = pd.read_csv('s3://music-lyrics-chain/g_df')#entire dataset, index, song_name, lyrics, genre\n",
    "#g_stop = pd.read_csv('s3://music-lyrics-chain/g_stopwords')#from 80% g_train dataset, domain specific stop words\n",
    "hiphop = pd.read_csv('s3://music-lyrics-chain/uniquely_hiphop')# from 80% g_train dataset, uniquely hiphop\n",
    "pop = pd.read_csv('s3://music-lyrics-chain/uniquely_pop')# from 80% g_train dataset, uniquely pop\n",
    "rock = pd.read_csv('s3://music-lyrics-chain/uniquely_rock')# from 80% g_train dataset, uniquely rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f82ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With appreciation for the Fake News Way\n",
    "def remove_special_characters(text): \n",
    "    \"\"\"\n",
    "    Removes special characters from the text document\n",
    "    \"\"\"\n",
    "    # define the pattern to keep. You can check the regex using this url https://regexr.com/\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def remove_extra_whitespace_tabs(text): \n",
    "    \"\"\"\n",
    "    Removes extra whitespaces and remove_extra_whitespace_tabs\n",
    "    \"\"\"\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()\n",
    "\n",
    "def remove_digits(text): \n",
    "    \"\"\"\n",
    "    Remove all digits from the text document\n",
    "     take string input and return a clean text without numbers.\n",
    "        Use regex to discard the numbers.\n",
    "    \"\"\"\n",
    "    result = ''.join(i for i in text if not i.isdigit()).lower()\n",
    "    return ' '.join(result.split())\n",
    "\n",
    "def remove_newlines(text): \n",
    "    \"\"\"\n",
    "    Remove newline characters from the text document\n",
    "    \"\"\"\n",
    "    return text.replace('\\\\n', ' ').replace('\\\\r', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\\\', ' ')\n",
    "\n",
    "#normalize to the NFKD (Normalization Form Compatibility Decomposition) form\n",
    "#that present in the Unicode standard to remain compatible with other encodings\n",
    "def remove_accented_chars(text): \n",
    "    \"\"\"\n",
    "    Removes accented characters from the test\n",
    "    \"\"\"\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "\n",
    "import contractions\n",
    "#contractions.fix(g_df['lyrics'][10])\n",
    "\n",
    "#expands contractions found in the text\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "# replace punctuation characters with spaces\n",
    "def replace_punctuation(text):\n",
    "    filters = string.punctuation + '”' + '“' + '–' + '!' + '?' + '.' + ',' #added !, ?, . , and comma\n",
    "    translate_dict = dict((c, \" \") for c in filters)   \n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def stops_letters(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stopword:\n",
    "            result.append(token)\n",
    "            \n",
    "    return \" \".join(result)\n",
    "\n",
    "#Removes any word that starts with either http or https\n",
    "def remove_urls(vTEXT):\n",
    "    #vTEXT = re.sub('http://\\S+|https://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    vTEXT = re.sub('http[s]?://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "#Remove words that starts with www\n",
    "def remove_www(vTEXT):\n",
    "    vTEXT = re.sub('www\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b951598e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 94804 entries, 0 to 94804\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  94804 non-null  int64 \n",
      " 1   All         94804 non-null  object\n",
      " 2   0           94804 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "g_stop = g_stop.dropna(subset=['All'])\n",
    "g_stop.info()#confirm this fixed a known issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bfcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bf22c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More Than This</td>\n",
       "      <td>I could feel at the time. There was no way of ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because The Night</td>\n",
       "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These Are Days</td>\n",
       "      <td>These are. These are days you'll remember. Nev...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 song_name                                             lyrics genre\n",
       "0           More Than This  I could feel at the time. There was no way of ...  Rock\n",
       "1        Because The Night  Take me now, baby, here as I am. Hold me close...  Rock\n",
       "2           These Are Days  These are. These are days you'll remember. Nev...  Rock\n",
       "3          A Campfire Song  A lie to say, \"O my mountain has coal veins an...  Rock\n",
       "4  Everyday Is Like Sunday  Trudging slowly over wet sand. Back to the ben...  Rock"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6c19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard NLP run through.\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_urls)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_www)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_special_characters)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_extra_whitespace_tabs)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_digits)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(remove_accented_chars)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(expand_contractions)\n",
    "g_df['lyrics'] = g_df['lyrics'].apply(replace_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de35a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an augist day in the hills of spain   a pair of children emerged from a cave   the strangest sight there alone they stood   with skin of green and words no one had heard   the girl was stronger  the boy was weak   with her new mother she learned to speak   and wove a tale of a dying sun   they had left darkness  a dark world come undone   they travelled so far   believing they came from a star   she fell through life  through time  through parallel lives   the men of science  the men of fame   the men of letters tried to explain   was it parallel worlds or a twist of time  to make her think she would fallen from the sky   a whirlwind spun them all alone   took them from their twilight home   believing they came from a star  '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda1ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word counts\n",
    "g_df['full_word_count'] = g_df[\"lyrics\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "g_df['full_character_count'] = g_df[\"lyrics\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "g_df['full_avg_word_length'] = g_df['full_character_count'] / g_df['full_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d2a859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   song_name             86294 non-null  object \n",
      " 1   lyrics                86294 non-null  object \n",
      " 2   genre                 86294 non-null  object \n",
      " 3   full_word_count       86294 non-null  int64  \n",
      " 4   full_character_count  86294 non-null  int64  \n",
      " 5   full_avg_word_length  86294 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a4dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gensim stopword removal.  Creating a medium sized lyrics set.  I'll run a couple feature engineering\n",
    "#functions on it.  Then create a smaller set with the domain specific stopwords list and compare the two.\n",
    "g_df['med_lyrics'] =g_df['lyrics'].apply(stops_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db27bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word counts\n",
    "g_df['med_word_count'] = g_df[\"med_lyrics\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "g_df['med_character_count'] = g_df[\"med_lyrics\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "g_df['med_avg_word_length'] = g_df['med_character_count'] / g_df['med_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4768053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   song_name             86294 non-null  object \n",
      " 1   lyrics                86294 non-null  object \n",
      " 2   genre                 86294 non-null  object \n",
      " 3   full_word_count       86294 non-null  int64  \n",
      " 4   full_character_count  86294 non-null  int64  \n",
      " 5   full_avg_word_length  86294 non-null  float64\n",
      " 6   med_lyrics            86294 non-null  object \n",
      " 7   med_word_count        86294 non-null  int64  \n",
      " 8   med_character_count   86294 non-null  int64  \n",
      " 9   med_avg_word_length   86294 non-null  float64\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a77f3be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augist day hills spain pair children emerged cave strangest sight stood skin green words heard girl stronger boy weak new mother learned speak wove tale dying sun left darkness dark world come undone travelled far believing came star fell life time parallel lives men science men fame men letters tried explain parallel worlds twist time think fallen sky whirlwind spun took twilight home believing came star'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['med_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12181e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['med_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "685bf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:22:02.394337\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd11c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:26:19.521217\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, Affinity score.\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "def get_affinity_scores(lyrics):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    for t in lyrics:\n",
    "        if len(t) > 0:\n",
    "            scores.append(afinn.score(t) / len(t))\n",
    "        else:\n",
    "            count += 1\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "new_affin = get_affinity_scores(g_df['med_lyrics'].tolist())\n",
    "\n",
    "g_df['med_content_affin'] = new_affin\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f38888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:32:28.254643\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07aa35",
   "metadata": {},
   "source": [
    "Something was broken in this.  The sent_score was always the same number \n",
    "and the labels were incorrect sometimes.  I fixed it with some changes however\n",
    "the med_sent_score is cast as a list, an object.  Need it as a Float for ML pipeline.\n",
    "\n",
    "Will fix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be6bf646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label done. Current Time = 2021-06-08 14:33:04.082967\n",
      "Both med_sent tasks done. Current Time = 2021-06-08 14:33:37.066180\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, Sentiment score and label\n",
    "\n",
    "def sentiment_check (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    if polarity_score < 0:\n",
    "        return 'negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "g_df['med_sent_label'] = g_df['med_lyrics'].apply(sentiment_check)\n",
    "\n",
    "print(\"Label done. Current Time =\", datetime.now())\n",
    "\n",
    "def new_sent_ck (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    sent_score = []\n",
    "    sent_score.append(polarity_score)\n",
    "    return sent_score\n",
    "\n",
    "g_df['med_sent_score'] = g_df['med_lyrics'].apply(new_sent_ck) \n",
    "\n",
    "print(\"Both med_sent tasks done. Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c79529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   song_name             86294 non-null  object \n",
      " 1   lyrics                86294 non-null  object \n",
      " 2   genre                 86294 non-null  object \n",
      " 3   full_word_count       86294 non-null  int64  \n",
      " 4   full_character_count  86294 non-null  int64  \n",
      " 5   full_avg_word_length  86294 non-null  float64\n",
      " 6   med_lyrics            86294 non-null  object \n",
      " 7   med_word_count        86294 non-null  int64  \n",
      " 8   med_character_count   86294 non-null  int64  \n",
      " 9   med_avg_word_length   86294 non-null  float64\n",
      " 10  med_content_affin     86294 non-null  float64\n",
      " 11  med_sent_label        86294 non-null  object \n",
      " 12  med_sent_score        86294 non-null  object \n",
      "dtypes: float64(3), int64(4), object(6)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108dac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df['med_sent_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adce24e",
   "metadata": {},
   "source": [
    "Need it as a Float..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0233c493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['med_sent_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a3b823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.061079545454545456]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['med_sent_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed7fe06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['med_sent_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed60c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:38:21.592758\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a7607e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:39:23.391426\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, giant string for a vectorizer, later.\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "def lemmatized_word(text):\n",
    "\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return  \" \".join(lemmatized_word) #combine the words into a giant string that vectorizer can accept\n",
    "\n",
    "g_df['med_vector'] = g_df['med_lyrics'].apply(lemmatized_word)\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df614ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   song_name             86294 non-null  object \n",
      " 1   lyrics                86294 non-null  object \n",
      " 2   genre                 86294 non-null  object \n",
      " 3   full_word_count       86294 non-null  int64  \n",
      " 4   full_character_count  86294 non-null  int64  \n",
      " 5   full_avg_word_length  86294 non-null  float64\n",
      " 6   med_lyrics            86294 non-null  object \n",
      " 7   med_word_count        86294 non-null  int64  \n",
      " 8   med_character_count   86294 non-null  int64  \n",
      " 9   med_avg_word_length   86294 non-null  float64\n",
      " 10  med_content_affin     86294 non-null  float64\n",
      " 11  med_sent_label        86294 non-null  object \n",
      " 12  med_sent_score        86294 non-null  object \n",
      " 13  med_vector            86294 non-null  object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01b728d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augist day hill spain pair child emerged cave strangest sight stood skin green word heard girl stronger boy weak new mother learned speak wove tale dying sun left darkness dark world come undone travelled far believing came star fell life time parallel life men science men fame men letter tried explain parallel world twist time think fallen sky whirlwind spun took twilight home believing came star'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['med_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d866cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['med_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37a4dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 14:43:16.510021\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e9c5594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23091 Rock!\n",
      "Current Time = 2021-06-08 14:43:19.525702\n",
      "29843 Hip Hop\n",
      "Current Time = 2021-06-08 15:23:33.054847\n",
      "13757 Pop\n",
      "Current Time = 2021-06-08 16:28:44.141510\n",
      "Current Time = 2021-06-08 16:50:21.369156\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, create domain specific scores based on words unique to particulary genres.\n",
    "def genre_count(text):\n",
    "    result = 0\n",
    "    text_tokenized = word_tokenize(text)\n",
    "    for i in range(0, len(text_tokenized)):\n",
    "        if text_tokenized[i] in stop_words:\n",
    "            result += digit\n",
    "        else:\n",
    "            pass\n",
    "    if result != 0:\n",
    "        return result\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Set Rock! words...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "rock2 = rock['Word'].to_dict()\n",
    "rock3 = list(rock2.values())\n",
    "digit = .01\n",
    "\n",
    "stop_words.extend(rock3)\n",
    "print(len(stop_words), 'Rock!')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Rock!\n",
    "g_df['med_rock_genre_count'] =g_df['med_lyrics'].apply(genre_count)\n",
    "\n",
    "#Reset to Hip Hop...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "hiphop2 = hiphop['Word'].to_dict()\n",
    "hiphop3 = list(hiphop2.values())\n",
    "digit = 100\n",
    "\n",
    "stop_words.extend(hiphop3)\n",
    "print(len(stop_words), 'Hip Hop')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Hip Hop\n",
    "g_df['med_hiphop_genre_count'] =g_df['med_lyrics'].apply(genre_count)\n",
    "\n",
    "#Reset to Pop...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "pop2 = pop['Word'].to_dict()\n",
    "pop3 = list(pop2.values())\n",
    "digit = 1\n",
    "\n",
    "stop_words.extend(pop3)\n",
    "print(len(stop_words), 'Pop')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Hip Hop\n",
    "g_df['med_pop_genre_count'] =g_df['med_lyrics'].apply(genre_count)\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac9e1924",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   song_name               86294 non-null  object \n",
      " 1   lyrics                  86294 non-null  object \n",
      " 2   genre                   86294 non-null  object \n",
      " 3   full_word_count         86294 non-null  int64  \n",
      " 4   full_character_count    86294 non-null  int64  \n",
      " 5   full_avg_word_length    86294 non-null  float64\n",
      " 6   med_lyrics              86294 non-null  object \n",
      " 7   med_word_count          86294 non-null  int64  \n",
      " 8   med_character_count     86294 non-null  int64  \n",
      " 9   med_avg_word_length     86294 non-null  float64\n",
      " 10  med_content_affin       86294 non-null  float64\n",
      " 11  med_sent_label          86294 non-null  object \n",
      " 12  med_sent_score          86294 non-null  object \n",
      " 13  med_vector              86294 non-null  object \n",
      " 14  med_rock_genre_count    19381 non-null  float64\n",
      " 15  med_hiphop_genre_count  13990 non-null  float64\n",
      " 16  med_pop_genre_count     8627 non-null   float64\n",
      "dtypes: float64(6), int64(4), object(7)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a62042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['med_pop_genre_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b9d8ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_name                                                    Green Children\n",
       "lyrics                    an augist day in the hills of spain   a pair o...\n",
       "genre                                                                  Rock\n",
       "full_word_count                                                         177\n",
       "full_character_count                                                    558\n",
       "full_avg_word_length                                               3.152542\n",
       "med_lyrics                augist day hills spain pair children emerged c...\n",
       "med_word_count                                                           66\n",
       "med_character_count                                                     343\n",
       "med_avg_word_length                                                 5.19697\n",
       "med_content_affin                                                 -0.012255\n",
       "med_sent_label                                                     negative\n",
       "med_sent_score                                      [-0.061079545454545456]\n",
       "med_vector                augist day hill spain pair child emerged cave ...\n",
       "med_rock_genre_count                                                   0.02\n",
       "med_hiphop_genre_count                                                  NaN\n",
       "med_pop_genre_count                                                     NaN\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.loc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd9af9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://final-music-flow.s3.amazonaws.com/g_df_final_halfway'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.to_csv('g_df_final_halfway')\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, file_path):\n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    file_dir, file_name = os.path.split(file_path)\n",
    "\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    bucket.upload_file(\n",
    "      Filename=file_path,\n",
    "      Key=file_name,\n",
    "      ExtraArgs={'ACL': 'private'}\n",
    "    )\n",
    "\n",
    "    s3_url = f\"https://{bucket_name}.s3.amazonaws.com/{file_name}\"\n",
    "    return s3_url\n",
    "\n",
    "\n",
    "\n",
    "upload_file_to_bucket('final-music-flow','g_df_final_halfway')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaeb90",
   "metadata": {},
   "source": [
    "Start the domain-specific round of smoothing and feature engineering.\n",
    "\n",
    "Next step is to use the domain-specific stopwords list with NLTK stopwords function (and list of ~170 words).  Will run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4215c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94983"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "g_stop2 = g_stop['All'].to_dict()\n",
    "g_stop3 = list(g_stop2.values())\n",
    "stop_words.extend(g_stop3)\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a8f5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words.extend(g_stop3)\n",
    "\n",
    "def stops_word(text):\n",
    "    result = []\n",
    "    text_tokenized = word_tokenize(text)\n",
    "    for i in range(0, len(text_tokenized)):\n",
    "        if text_tokenized[i] not in stop_words:\n",
    "            result.append(text_tokenized[i])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    return str(result).replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37c1b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-08 18:03:44.846767\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50b43ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-09 06:48:29.850277\n"
     ]
    }
   ],
   "source": [
    "g_df['sml_lyrics'] =g_df['lyrics'].apply(stops_word)\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ae9e3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   song_name               86294 non-null  object \n",
      " 1   lyrics                  86294 non-null  object \n",
      " 2   genre                   86294 non-null  object \n",
      " 3   full_word_count         86294 non-null  int64  \n",
      " 4   full_character_count    86294 non-null  int64  \n",
      " 5   full_avg_word_length    86294 non-null  float64\n",
      " 6   med_lyrics              86294 non-null  object \n",
      " 7   med_word_count          86294 non-null  int64  \n",
      " 8   med_character_count     86294 non-null  int64  \n",
      " 9   med_avg_word_length     86294 non-null  float64\n",
      " 10  med_content_affin       86294 non-null  float64\n",
      " 11  med_sent_label          86294 non-null  object \n",
      " 12  med_sent_score          86294 non-null  object \n",
      " 13  med_vector              86294 non-null  object \n",
      " 14  med_rock_genre_count    19381 non-null  float64\n",
      " 15  med_hiphop_genre_count  13990 non-null  float64\n",
      " 16  med_pop_genre_count     8627 non-null   float64\n",
      " 17  sml_lyrics              86294 non-null  object \n",
      "dtypes: float64(6), int64(4), object(8)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a783e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['sml_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db50dabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[day, hills, spain, pair, children, cave, strangest, sight, alone, stood, skin, green, words, one, heard, girl, stronger, boy, weak, new, mother, learned, speak, tale, dying, sun, left, darkness, dark, world, come, undone, travelled, far, believing, came, star, fell, life, time, parallel, lives, men, science, men, fame, men, letters, tried, explain, parallel, worlds, twist, time, make, think, would, fallen, sky, whirlwind, spun, alone, took, twilight, home, believing, came, star]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['sml_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "080ce176",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['sml_lyrics']=g_df['sml_lyrics'].str.replace(',' ,'')# Fixes the srings with commas issue.\n",
    "g_df['sml_lyrics']=g_df['sml_lyrics'].str.replace('[' ,'')\n",
    "g_df['sml_lyrics']=g_df['sml_lyrics'].str.replace(']' ,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f3d045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day hills spain pair children cave strangest sight alone stood skin green words one heard girl stronger boy weak new mother learned speak tale dying sun left darkness dark world come undone travelled far believing came star fell life time parallel lives men science men fame men letters tried explain parallel worlds twist time make think would fallen sky whirlwind spun alone took twilight home believing came star'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['sml_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ae07104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word counts\n",
    "g_df['sml_word_count'] = g_df[\"sml_lyrics\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "g_df['sml_character_count'] = g_df[\"sml_lyrics\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "g_df['sml_avg_word_length'] = g_df['sml_character_count'] / g_df['sml_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af73aa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11371013"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total words after domain-specific stopwords but before gensim stopwords.\n",
    "g_df['sml_word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dcc912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gensim stopword removal.  Same as what was run on med_lyrics.  IOT limit differences between \n",
    "#sml_ and med_ portions of dataset to just domain-specific stopwords and scoring.\n",
    "\n",
    "g_df['sml_lyrics'] = g_df['sml_lyrics'].apply(stops_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa35fbc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8830376"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df['sml_word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79bdcc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9358663"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df['med_word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c62e10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-09 06:56:52.967291\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22b0e403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-09 07:00:50.880932\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, Affinity score.\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "new_affin = get_affinity_scores(g_df['sml_lyrics'].tolist())\n",
    "\n",
    "g_df['sml_content_affin'] = new_affin\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9ea57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-09 07:01:52.115977\n",
      "Label done. Current Time = 2021-06-09 07:02:24.116838\n",
      "Both sml_sent tasks done. Current Time = 2021-06-09 07:02:55.707841\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, Sentiment score and label\n",
    "\n",
    "\"\"\" Something was broken in this.  The sent_score was always the same number \n",
    "and the labels were incorrect sometimes.  I fixed it with some changes, however\n",
    "the sml_sent_score is cast as a list, an object.  Need it as a Float.\n",
    "\n",
    "Will fix later.\"\"\"\n",
    "\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "def sentiment_check (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    if polarity_score < 0:\n",
    "        return 'negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "g_df['sml_sent_label'] = g_df['sml_lyrics'].apply(sentiment_check)\n",
    "\n",
    "print(\"Label done. Current Time =\", datetime.now())\n",
    "\n",
    "def new_sent_ck (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    sent_score = []\n",
    "    sent_score.append(polarity_score)\n",
    "    return sent_score\n",
    "\n",
    "g_df['sml_sent_score'] = g_df['sml_lyrics'].apply(new_sent_ck) \n",
    "\n",
    "print(\"Both sml_sent tasks done. Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3a9f6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 2021-06-09 07:03:18.487704\n",
      "Current Time = 2021-06-09 07:04:12.593434\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, giant string for a vectorizer, later.\n",
    "\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "g_df['sml_vector'] = g_df['sml_lyrics'].apply(lemmatized_word)\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b247c8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86294 entries, 0 to 86293\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   song_name               86294 non-null  object \n",
      " 1   lyrics                  86294 non-null  object \n",
      " 2   genre                   86294 non-null  object \n",
      " 3   full_word_count         86294 non-null  int64  \n",
      " 4   full_character_count    86294 non-null  int64  \n",
      " 5   full_avg_word_length    86294 non-null  float64\n",
      " 6   med_lyrics              86294 non-null  object \n",
      " 7   med_word_count          86294 non-null  int64  \n",
      " 8   med_character_count     86294 non-null  int64  \n",
      " 9   med_avg_word_length     86294 non-null  float64\n",
      " 10  med_content_affin       86294 non-null  float64\n",
      " 11  med_sent_label          86294 non-null  object \n",
      " 12  med_sent_score          86294 non-null  object \n",
      " 13  med_vector              86294 non-null  object \n",
      " 14  med_rock_genre_count    19381 non-null  float64\n",
      " 15  med_hiphop_genre_count  13990 non-null  float64\n",
      " 16  med_pop_genre_count     8627 non-null   float64\n",
      " 17  sml_lyrics              86294 non-null  object \n",
      " 18  sml_word_count          86294 non-null  int64  \n",
      " 19  sml_character_count     86294 non-null  int64  \n",
      " 20  sml_avg_word_length     86294 non-null  float64\n",
      " 21  sml_content_affin       86294 non-null  float64\n",
      " 22  sml_sent_label          86294 non-null  object \n",
      " 23  sml_sent_score          86294 non-null  object \n",
      " 24  sml_vector              86294 non-null  object \n",
      "dtypes: float64(8), int64(6), object(11)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24cb392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g_df.iloc[50]['sml_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "248f840f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day hill spain pair child cave strangest sight stood skin green word heard girl stronger boy weak new mother learned speak tale dying sun left darkness dark world come undone travelled far believing came star fell life time parallel life men science men fame men letter tried explain parallel world twist time think fallen sky whirlwind spun took twilight home believing came star'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.iloc[50]['sml_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26422e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://final-music-flow.s3.amazonaws.com/g_df_final_most_the_way'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.to_csv('g_df_final_most_the_way')\n",
    "\n",
    "upload_file_to_bucket('final-music-flow','g_df_final_most_the_way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6437a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = pd.read_csv('s3://final-music-flow/g_df_final_most_the_way') #complete, final dataset - less the sml_genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0447763c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86290 entries, 0 to 86293\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              86290 non-null  int64  \n",
      " 1   song_name               86290 non-null  object \n",
      " 2   lyrics                  86290 non-null  object \n",
      " 3   genre                   86290 non-null  object \n",
      " 4   full_word_count         86290 non-null  int64  \n",
      " 5   full_character_count    86290 non-null  int64  \n",
      " 6   full_avg_word_length    86290 non-null  float64\n",
      " 7   med_lyrics              86290 non-null  object \n",
      " 8   med_word_count          86290 non-null  int64  \n",
      " 9   med_character_count     86290 non-null  int64  \n",
      " 10  med_avg_word_length     86290 non-null  float64\n",
      " 11  med_content_affin       86290 non-null  float64\n",
      " 12  med_sent_label          86290 non-null  object \n",
      " 13  med_sent_score          86290 non-null  object \n",
      " 14  med_vector              86290 non-null  object \n",
      " 15  med_rock_genre_count    19380 non-null  float64\n",
      " 16  med_hiphop_genre_count  13990 non-null  float64\n",
      " 17  med_pop_genre_count     8627 non-null   float64\n",
      " 18  sml_lyrics              86290 non-null  object \n",
      " 19  sml_word_count          86290 non-null  int64  \n",
      " 20  sml_character_count     86290 non-null  int64  \n",
      " 21  sml_avg_word_length     86290 non-null  float64\n",
      " 22  sml_content_affin       86290 non-null  float64\n",
      " 23  sml_sent_label          86290 non-null  object \n",
      " 24  sml_sent_score          86290 non-null  object \n",
      " 25  sml_vector              86290 non-null  object \n",
      "dtypes: float64(8), int64(7), object(11)\n",
      "memory usage: 17.8+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d3f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up NaN values, which will stop the genre_count function below.\n",
    "g_df.dropna(axis=0, subset=['sml_lyrics'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3769ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23091 Rock!\n",
      "Current Time = 2021-06-09 16:17:51.449676\n",
      "29843 Hip Hop\n",
      "Current Time = 2021-06-09 16:51:20.023943\n",
      "13757 Pop\n",
      "Current Time = 2021-06-09 17:38:52.220396\n",
      "Current Time = 2021-06-09 17:59:23.716548\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering, create domain specific scores based on words unique to particulary genres.\n",
    "\n",
    "def genre_count(text):\n",
    "    result = 0\n",
    "    text_tokenized = word_tokenize(text)\n",
    "    for i in range(0, len(text_tokenized)):\n",
    "        if text_tokenized[i] in stop_words:\n",
    "            result += digit\n",
    "        else:\n",
    "            pass\n",
    "    if result != 0:\n",
    "        return result\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Set Rock! words...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "rock2 = rock['Word'].to_dict()\n",
    "rock3 = list(rock2.values())\n",
    "digit = .01\n",
    "\n",
    "stop_words.extend(rock3)\n",
    "print(len(stop_words), 'Rock!')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Rock!\n",
    "g_df['sml_rock_genre_count'] =g_df['sml_lyrics'].apply(genre_count)\n",
    "\n",
    "#Reset to Hip Hop...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "hiphop2 = hiphop['Word'].to_dict()\n",
    "hiphop3 = list(hiphop2.values())\n",
    "digit = 100\n",
    "\n",
    "stop_words.extend(hiphop3)\n",
    "print(len(stop_words), 'Hip Hop')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Hip Hop\n",
    "g_df['sml_hiphop_genre_count'] =g_df['sml_lyrics'].apply(genre_count)\n",
    "\n",
    "#Reset to Pop...\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "pop2 = pop['Word'].to_dict()\n",
    "pop3 = list(pop2.values())\n",
    "digit = 1\n",
    "\n",
    "stop_words.extend(pop3)\n",
    "print(len(stop_words), 'Pop')\n",
    "print(\"Current Time =\", datetime.now())\n",
    "\n",
    "#Run genre_count with Hip Hop\n",
    "g_df['sml_pop_genre_count'] =g_df['sml_lyrics'].apply(genre_count)\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6258bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86290 entries, 0 to 86293\n",
      "Data columns (total 29 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              86290 non-null  int64  \n",
      " 1   song_name               86290 non-null  object \n",
      " 2   lyrics                  86290 non-null  object \n",
      " 3   genre                   86290 non-null  object \n",
      " 4   full_word_count         86290 non-null  int64  \n",
      " 5   full_character_count    86290 non-null  int64  \n",
      " 6   full_avg_word_length    86290 non-null  float64\n",
      " 7   med_lyrics              86290 non-null  object \n",
      " 8   med_word_count          86290 non-null  int64  \n",
      " 9   med_character_count     86290 non-null  int64  \n",
      " 10  med_avg_word_length     86290 non-null  float64\n",
      " 11  med_content_affin       86290 non-null  float64\n",
      " 12  med_sent_label          86290 non-null  object \n",
      " 13  med_sent_score          86290 non-null  object \n",
      " 14  med_vector              86290 non-null  object \n",
      " 15  med_rock_genre_count    86290 non-null  float64\n",
      " 16  med_hiphop_genre_count  86290 non-null  float64\n",
      " 17  med_pop_genre_count     86290 non-null  float64\n",
      " 18  sml_lyrics              86290 non-null  object \n",
      " 19  sml_word_count          86290 non-null  int64  \n",
      " 20  sml_character_count     86290 non-null  int64  \n",
      " 21  sml_avg_word_length     86290 non-null  float64\n",
      " 22  sml_content_affin       86290 non-null  float64\n",
      " 23  sml_sent_label          86290 non-null  object \n",
      " 24  sml_sent_score          86290 non-null  object \n",
      " 25  sml_vector              86290 non-null  object \n",
      " 26  sml_rock_genre_count    86290 non-null  float64\n",
      " 27  sml_hiphop_genre_count  86290 non-null  float64\n",
      " 28  sml_pop_genre_count     86290 non-null  float64\n",
      "dtypes: float64(11), int64(7), object(11)\n",
      "memory usage: 19.8+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada4849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e9984c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://final-music-flow.s3.amazonaws.com/g_df_final_almost_dun'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.to_csv('g_df_final_almost_dun')\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, file_path):\n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    file_dir, file_name = os.path.split(file_path)\n",
    "\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    bucket.upload_file(\n",
    "      Filename=file_path,\n",
    "      Key=file_name,\n",
    "      ExtraArgs={'ACL': 'private'}\n",
    "    )\n",
    "\n",
    "    s3_url = f\"https://{bucket_name}.s3.amazonaws.com/{file_name}\"\n",
    "    return s3_url\n",
    "\n",
    "upload_file_to_bucket('final-music-flow','g_df_final_almost_dun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e299f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['med_rock_genre_count'] = g_df['med_rock_genre_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f00b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['med_hiphop_genre_count'] = g_df['med_hiphop_genre_count'].fillna(0)\n",
    "g_df['med_pop_genre_count'] = g_df['med_pop_genre_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12776bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['sml_rock_genre_count'] = g_df['sml_rock_genre_count'].fillna(0)\n",
    "g_df['sml_hiphop_genre_count'] = g_df['sml_hiphop_genre_count'].fillna(0)\n",
    "g_df['sml_pop_genre_count'] = g_df['sml_pop_genre_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6387ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['med_genre_count'] = g_df['med_rock_genre_count']+g_df['med_hiphop_genre_count']+g_df['med_pop_genre_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "791589b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df['sml_genre_count'] = g_df['sml_rock_genre_count']+g_df['sml_hiphop_genre_count']+g_df['sml_pop_genre_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d48658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86290 entries, 0 to 86293\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              86290 non-null  int64  \n",
      " 1   song_name               86290 non-null  object \n",
      " 2   lyrics                  86290 non-null  object \n",
      " 3   genre                   86290 non-null  object \n",
      " 4   full_word_count         86290 non-null  int64  \n",
      " 5   full_character_count    86290 non-null  int64  \n",
      " 6   full_avg_word_length    86290 non-null  float64\n",
      " 7   med_lyrics              86290 non-null  object \n",
      " 8   med_word_count          86290 non-null  int64  \n",
      " 9   med_character_count     86290 non-null  int64  \n",
      " 10  med_avg_word_length     86290 non-null  float64\n",
      " 11  med_content_affin       86290 non-null  float64\n",
      " 12  med_sent_label          86290 non-null  object \n",
      " 13  med_sent_score          86290 non-null  object \n",
      " 14  med_vector              86290 non-null  object \n",
      " 15  med_rock_genre_count    86290 non-null  float64\n",
      " 16  med_hiphop_genre_count  86290 non-null  float64\n",
      " 17  med_pop_genre_count     86290 non-null  float64\n",
      " 18  sml_lyrics              86290 non-null  object \n",
      " 19  sml_word_count          86290 non-null  int64  \n",
      " 20  sml_character_count     86290 non-null  int64  \n",
      " 21  sml_avg_word_length     86290 non-null  float64\n",
      " 22  sml_content_affin       86290 non-null  float64\n",
      " 23  sml_sent_label          86290 non-null  object \n",
      " 24  sml_sent_score          86290 non-null  object \n",
      " 25  sml_vector              86290 non-null  object \n",
      " 26  sml_rock_genre_count    86290 non-null  float64\n",
      " 27  sml_hiphop_genre_count  86290 non-null  float64\n",
      " 28  sml_pop_genre_count     86290 non-null  float64\n",
      " 29  med_genre_count         86290 non-null  float64\n",
      " 30  sml_genre_count         86290 non-null  float64\n",
      "dtypes: float64(13), int64(7), object(11)\n",
      "memory usage: 21.1+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cd7a705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>full_word_count</th>\n",
       "      <th>full_character_count</th>\n",
       "      <th>full_avg_word_length</th>\n",
       "      <th>med_lyrics</th>\n",
       "      <th>med_word_count</th>\n",
       "      <th>med_character_count</th>\n",
       "      <th>med_avg_word_length</th>\n",
       "      <th>med_content_affin</th>\n",
       "      <th>med_sent_label</th>\n",
       "      <th>med_sent_score</th>\n",
       "      <th>med_vector</th>\n",
       "      <th>med_rock_genre_count</th>\n",
       "      <th>med_hiphop_genre_count</th>\n",
       "      <th>med_pop_genre_count</th>\n",
       "      <th>sml_lyrics</th>\n",
       "      <th>sml_word_count</th>\n",
       "      <th>sml_character_count</th>\n",
       "      <th>sml_avg_word_length</th>\n",
       "      <th>sml_content_affin</th>\n",
       "      <th>sml_sent_label</th>\n",
       "      <th>sml_sent_score</th>\n",
       "      <th>sml_vector</th>\n",
       "      <th>sml_rock_genre_count</th>\n",
       "      <th>sml_hiphop_genre_count</th>\n",
       "      <th>sml_pop_genre_count</th>\n",
       "      <th>med_genre_count</th>\n",
       "      <th>sml_genre_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>66799</td>\n",
       "      <td>86203</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>53904</td>\n",
       "      <td>85355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>53696</td>\n",
       "      <td>85264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Intro</td>\n",
       "      <td>so  so you think you can tell  heaven from hel...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaming white christmas like ones know treeto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>merry little christmas let heart light trouble...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feel like home feel like feel like young feel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>merry little christmas let heart light trouble...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>47406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58208</td>\n",
       "      <td>1447</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58255</td>\n",
       "      <td>1473</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43146.607150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355.093638</td>\n",
       "      <td>1067.958303</td>\n",
       "      <td>3.032924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.455858</td>\n",
       "      <td>552.463715</td>\n",
       "      <td>5.120146</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>91.105574</td>\n",
       "      <td>0.358106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.333666</td>\n",
       "      <td>509.263924</td>\n",
       "      <td>5.011926</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>5.672731</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>91.470013</td>\n",
       "      <td>5.687131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24911.499451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.656149</td>\n",
       "      <td>651.998326</td>\n",
       "      <td>0.300625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.646193</td>\n",
       "      <td>379.487446</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>351.449939</td>\n",
       "      <td>3.012329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.819909</td>\n",
       "      <td>338.198070</td>\n",
       "      <td>0.429539</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>110.012447</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>351.424018</td>\n",
       "      <td>110.014459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.493151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.503979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21573.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>638.000000</td>\n",
       "      <td>2.853833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>-0.012953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43146.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>908.000000</td>\n",
       "      <td>3.026846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>4.982759</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64720.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>1303.000000</td>\n",
       "      <td>3.206452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>5.256850</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>86293.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4723.000000</td>\n",
       "      <td>13407.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>7212.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.462428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1278.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>17700.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>17700.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0 song_name                                             lyrics  genre  full_word_count  full_character_count  full_avg_word_length                                         med_lyrics  med_word_count  med_character_count  med_avg_word_length  med_content_affin med_sent_label med_sent_score                                         med_vector  med_rock_genre_count  med_hiphop_genre_count  med_pop_genre_count                                         sml_lyrics  sml_word_count  sml_character_count  sml_avg_word_length  sml_content_affin sml_sent_label sml_sent_score                                         sml_vector  sml_rock_genre_count  sml_hiphop_genre_count  sml_pop_genre_count  med_genre_count  sml_genre_count\n",
       "count   86290.000000     86290                                              86290  86290     86290.000000          86290.000000          86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290          86290                                              86290          86290.000000            86290.000000         86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290          86290                                              86290          86290.000000            86290.000000         86290.000000     86290.000000     86290.000000\n",
       "unique           NaN     66799                                              86203      3              NaN                   NaN                   NaN                                              85378             NaN                  NaN                  NaN                NaN              3          53904                                              85355                   NaN                     NaN                  NaN                                              85286             NaN                  NaN                  NaN                NaN              3          53696                                              85264                   NaN                     NaN                  NaN              NaN              NaN\n",
       "top              NaN     Intro  so  so you think you can tell  heaven from hel...   Rock              NaN                   NaN                   NaN  dreaming white christmas like ones know treeto...             NaN                  NaN                  NaN                NaN       positive          [0.0]  merry little christmas let heart light trouble...                   NaN                     NaN                  NaN  feel like home feel like feel like young feel ...             NaN                  NaN                  NaN                NaN       positive          [0.0]  merry little christmas let heart light trouble...                   NaN                     NaN                  NaN              NaN              NaN\n",
       "freq             NaN        50                                                  3  47406              NaN                   NaN                   NaN                                                  4             NaN                  NaN                  NaN                NaN          58208           1447                                                  4                   NaN                     NaN                  NaN                                                  4             NaN                  NaN                  NaN                NaN          58255           1473                                                  4                   NaN                     NaN                  NaN              NaN              NaN\n",
       "mean    43146.607150       NaN                                                NaN    NaN       355.093638           1067.958303              3.032924                                                NaN      108.455858           552.463715             5.120146           0.010880            NaN            NaN                                                NaN              0.006332               91.105574             0.358106                                                NaN      102.333666           509.263924             5.011926           0.011444            NaN            NaN                                                NaN              0.000238                5.672731             0.014162        91.470013         5.687131\n",
       "std     24911.499451       NaN                                                NaN    NaN       218.656149            651.998326              0.300625                                                NaN       74.646193           379.487446             0.467359           0.046185            NaN            NaN                                                NaN              0.021912              351.449939             3.012329                                                NaN       68.819909           338.198070             0.429539           0.048637            NaN            NaN                                                NaN              0.006379              110.012447             0.774038       351.424018       110.014459\n",
       "min         0.000000       NaN                                                NaN    NaN         1.000000              8.000000              0.051852                                                NaN        1.000000             4.000000             3.000000          -0.493151            NaN            NaN                                                NaN              0.000000                0.000000             0.000000                                                NaN        1.000000             4.000000             3.000000          -0.503979            NaN            NaN                                                NaN              0.000000                0.000000             0.000000         0.000000         0.000000\n",
       "25%     21573.250000       NaN                                                NaN    NaN       209.000000            638.000000              2.853833                                                NaN       61.000000           312.000000             4.812500          -0.012953            NaN            NaN                                                NaN              0.000000                0.000000             0.000000                                                NaN       58.000000           291.000000             4.733333          -0.013661            NaN            NaN                                                NaN              0.000000                0.000000             0.000000         0.000000         0.000000\n",
       "50%     43146.500000       NaN                                                NaN    NaN       299.000000            908.000000              3.026846                                                NaN       88.000000           450.000000             5.083333           0.008451            NaN            NaN                                                NaN              0.000000                0.000000             0.000000                                                NaN       84.000000           421.000000             4.982759           0.009302            NaN            NaN                                                NaN              0.000000                0.000000             0.000000         0.000000         0.000000\n",
       "75%     64720.750000       NaN                                                NaN    NaN       436.000000           1303.000000              3.206452                                                NaN      129.000000           661.000000             5.384615           0.032754            NaN            NaN                                                NaN              0.000000                0.000000             0.000000                                                NaN      123.000000           615.000000             5.256850           0.034800            NaN            NaN                                                NaN              0.000000                0.000000             0.000000         0.120000         0.000000\n",
       "max     86293.000000       NaN                                                NaN    NaN      4723.000000          13407.000000              9.000000                                                NaN     1380.000000          7212.000000            12.000000           0.462428            NaN            NaN                                                NaN              0.970000            18100.000000           197.000000                                                NaN     1278.000000          6486.000000            12.000000           0.500000            NaN            NaN                                                NaN              0.660000            17700.000000            91.000000     18100.000000     17700.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c38b1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec55c51e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://final-music-flow.s3.amazonaws.com/g_df_final_fix_obj'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.to_csv('g_df_final_fix_obj')\n",
    "\n",
    "upload_file_to_bucket('final-music-flow','g_df_final_fix_obj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
