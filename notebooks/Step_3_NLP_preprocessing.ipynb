{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b673b64",
   "metadata": {},
   "source": [
    "First time through, following the Fake_News method (https://github.com/georgetown-analytics/From-Russia-With-Love-fake-news-/blob/master/Notebooks/Step_1_Data_Cleaning.ipynb).  \n",
    "\n",
    "We explore different options in other NBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867d7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1613962be9f5>:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100000)\n",
    "pd.set_option('display.max_row', 1000000)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "# import tldextract \"\"\"Accurately separate the TLD from the registered domain and subdomains of a URL\"\"\"\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\", leave=False)\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang import punctuation\n",
    "import unicodedata  # might need to pip install unicodedate2 on aws sagemaker\n",
    "import contractions\n",
    "from contractions import contractions_dict ## pip installed this\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import warnings\n",
    "from afinn import Afinn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2',rc={'figure.figsize':(9,6),'figure.dpi':90})\n",
    "\n",
    "punctuation = string.punctuation + '”' + '“' + '–' + '““' + \"’’\" + '”'\n",
    "stopword = stopwords.words('english')\n",
    "stopwords = set(STOPWORDS)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ffb8f",
   "metadata": {},
   "source": [
    "Download dataset from S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d911d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=False,key='###',secret='###')\n",
    "\n",
    "genres_df = pd.read_csv('s3://wrangled-1/merged5_genre_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60bd80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86391, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27282b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_csv', 'artist_name', 'song_name', 'link', 'lyrics',\n",
       "       'language', 'genre', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d957b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84304</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>taylor-swift</td>\n",
       "      <td>The Story Of Us</td>\n",
       "      <td>/taylor-swift/the-story-of-us.html</td>\n",
       "      <td>I used to think one day we'd tell the story of...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Pop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_csv   artist_name        song_name  \\\n",
       "84304   genres_csv  taylor-swift  The Story Of Us   \n",
       "\n",
       "                                     link  \\\n",
       "84304  /taylor-swift/the-story-of-us.html   \n",
       "\n",
       "                                                  lyrics language genre  date  \n",
       "84304  I used to think one day we'd tell the story of...  ENGLISH   Pop   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.loc[genres_df['song_name']=='The Story Of Us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ce06b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I used to think one day we'd tell the story of us. How we met and sparks flew instantly. People would say 'They're the lucky ones'. I used to know my place was a spot next to you. Now I'm searching the room for an empty seat. 'Cause lately I don't even know what page you're on. Oh. A simple complication, miscommunication. Has lead to fallout. Too many things that I wish you knew. So many walls up I can't break through. Now I'm standing alone in a crowded room. And we're not speaking. And I'm dying to know. Is it killing you like it's killing me?. And I don't know what to say. Since the twist of fate. When it all broke down. And the story of us looks a lot like a tragedy now. Next chapter. How'd we end up this way?. Se me nervously pulling at my clothes. And trying to look busy. And you're doing your best to avoid me. I'm starting to think one day I'll tell the story of us. How I was losing my mind when I saw you here. But you held your pride like you should've held me. Oh. I'm scared to see the ending. Why are we pretending this is nothing?. I'd tell you I miss you but I don't know how. I've never heard silence quite this loud. Now I'm standing alone in a crowded room. And we're not speaking. And I'm dying to know. Is it killing you like it's killing me?. And I don't know what to say. Since the twist of fate. When it all broke down. And the story of us looks a lot like a tragedy now. This is looking like a contest. Of who can act like they care less. But I liked it better when you were on my side. The battle's in your hands now. But I will lay my armor down. If you say you'd rather love than fight. So many things that you wish I knew. But the story of us might be ending soon. Now I'm standing alone in a crowded room. And we're not speaking. And I'm dying to know. Is it killing you like it's killing me?. But I don't know what to say. Since the twist of fate. And it all broke down. And the story of us looks a lot like a tragedy now. Now, now. And we're not speaking. And I'm dying to know. Is it killing you like it's killing me?. I don't know what to say. Since the twist of fate. 'Cause we're going down. And the story of us looks a lot like a tragedy now. The End\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed13015",
   "metadata": {},
   "source": [
    "Defining functions for first round of cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28f1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portions of this are excerpts from Stack Overflow responses\n",
    "def remove_special_characters(text): \n",
    "    \"\"\"\n",
    "    Removes special characters from the text document\n",
    "    \"\"\"\n",
    "    # define the pattern to keep. You can check the regex using this url https://regexr.com/\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def remove_extra_whitespace_tabs(text): \n",
    "    \"\"\"\n",
    "    Removes extra whitespaces and remove_extra_whitespace_tabs\n",
    "    \"\"\"\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()\n",
    "\n",
    "def remove_digits(text): \n",
    "    \"\"\"\n",
    "    Remove all digits from the text document\n",
    "     take string input and return a clean text without numbers.\n",
    "        Use regex to discard the numbers.\n",
    "    \"\"\"\n",
    "    result = ''.join(i for i in text if not i.isdigit()).lower()\n",
    "    return ' '.join(result.split())\n",
    "\n",
    "def remove_newlines(text): \n",
    "    \"\"\"\n",
    "    Remove newline characters from the text document\n",
    "    \"\"\"\n",
    "    return text.replace('\\\\n', ' ').replace('\\\\r', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\\\', ' ')\n",
    "\n",
    "#normalize to the NFKD (Normalization Form Compatibility Decomposition) form\n",
    "#that present in the Unicode standard to remain compatible with other encodings\n",
    "def remove_accented_chars(text): \n",
    "    \"\"\"\n",
    "    Removes accented characters from the test\n",
    "    \"\"\"\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "\n",
    "\n",
    "import contractions\n",
    "contractions.fix(genres_df['lyrics'][10])\n",
    "\n",
    "\n",
    "\n",
    "#expands contractions found in the text\n",
    "def expand_contractions(text):\n",
    "\n",
    "\n",
    "    #contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    #def expand_match(contraction):\n",
    "    #    match = contraction.group(0)\n",
    "    #    first_char = match[0]\n",
    "    #    expanded_contraction = contraction_mapping.get(match)\\\n",
    "    #                            if contraction_mapping.get(match)\\\n",
    "    #                            else contraction_mapping.get(match.lower())\n",
    "    #    expanded_contraction = first_char+expanded_contraction[1:]\n",
    "    #    return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions.fix(text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "# replace punctuation characters with spaces\n",
    "def replace_punctuation(text):\n",
    "    filters = string.punctuation + '”' + '“' + '–' \n",
    "    translate_dict = dict((c, \" \") for c in filters)   \n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def stops_letters(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stopword:\n",
    "            result.append(token)\n",
    "            \n",
    "    return \" \".join(result)\n",
    "\n",
    "#Removes any word that starts with either http or https\n",
    "def remove_urls(vTEXT):\n",
    "    #vTEXT = re.sub('http://\\S+|https://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    vTEXT = re.sub('http[s]?://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "#Remove words that starts with www\n",
    "def remove_www(vTEXT):\n",
    "    vTEXT = re.sub('www\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb27234",
   "metadata": {},
   "source": [
    "Convert Lyrics to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46380c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 42.4 ms, total: 203 ms\n",
      "Wall time: 202 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "genres_df['lyrics']=genres_df['lyrics'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9f3231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i used to think one day we'd tell the story of us. how we met and sparks flew instantly. people would say 'they're the lucky ones'. i used to know my place was a spot next to you. now i'm searching the room for an empty seat. 'cause lately i don't even know what page you're on. oh. a simple complication, miscommunication. has lead to fallout. too many things that i wish you knew. so many walls up i can't break through. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. and i don't know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. next chapter. how'd we end up this way?. se me nervously pulling at my clothes. and trying to look busy. and you're doing your best to avoid me. i'm starting to think one day i'll tell the story of us. how i was losing my mind when i saw you here. but you held your pride like you should've held me. oh. i'm scared to see the ending. why are we pretending this is nothing?. i'd tell you i miss you but i don't know how. i've never heard silence quite this loud. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. and i don't know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. this is looking like a contest. of who can act like they care less. but i liked it better when you were on my side. the battle's in your hands now. but i will lay my armor down. if you say you'd rather love than fight. so many things that you wish i knew. but the story of us might be ending soon. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. but i don't know what to say. since the twist of fate. and it all broke down. and the story of us looks a lot like a tragedy now. now, now. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. i don't know what to say. since the twist of fate. 'cause we're going down. and the story of us looks a lot like a tragedy now. the end\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b559081",
   "metadata": {},
   "source": [
    "Remove URLs, www, incase they are in the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1912c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 355 ms, sys: 3.25 ms, total: 358 ms\n",
      "Wall time: 356 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "genres_df['lyrics']=genres_df['lyrics'].apply(remove_urls)\n",
    "genres_df['lyrics']=genres_df['lyrics'].apply(remove_www)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37faf8",
   "metadata": {},
   "source": [
    "Remove special characters and extra whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b3282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.82 s, sys: 39.5 ms, total: 7.86 s\n",
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "genres_df['lyrics']=genres_df['lyrics'].apply(remove_special_characters)\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(remove_extra_whitespace_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69cf385",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i used to think one day we'd tell the story of us. how we met and sparks flew instantly. people would say 'they're the lucky ones'. i used to know my place was a spot next to you. now i'm searching the room for an empty seat. 'cause lately i don't even know what page you're on. oh. a simple complication, miscommunication. has lead to fallout. too many things that i wish you knew. so many walls up i can't break through. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. and i don't know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. next chapter. how'd we end up this way?. se me nervously pulling at my clothes. and trying to look busy. and you're doing your best to avoid me. i'm starting to think one day i'll tell the story of us. how i was losing my mind when i saw you here. but you held your pride like you should've held me. oh. i'm scared to see the ending. why are we pretending this is nothing?. i'd tell you i miss you but i don't know how. i've never heard silence quite this loud. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. and i don't know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. this is looking like a contest. of who can act like they care less. but i liked it better when you were on my side. the battle's in your hands now. but i will lay my armor down. if you say you'd rather love than fight. so many things that you wish i knew. but the story of us might be ending soon. now i'm standing alone in a crowded room. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. but i don't know what to say. since the twist of fate. and it all broke down. and the story of us looks a lot like a tragedy now. now, now. and we're not speaking. and i'm dying to know. is it killing you like it's killing me?. i don't know what to say. since the twist of fate. 'cause we're going down. and the story of us looks a lot like a tragedy now. the end\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a68a7",
   "metadata": {},
   "source": [
    "Remove digits, accented characters, contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbed9c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 62.8 ms, total: 19.3 s\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(remove_digits)\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(remove_accented_chars)\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08d73bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i used to think one day we would tell the story of us. how we met and sparks flew instantly. people would say they are the lucky ones. i used to know my place was a spot next to you. now I am searching the room for an empty seat. because lately i do not even know what page you are on. oh. a simple complication, miscommunication. has lead to fallout. too many things that i wish you knew. so many walls up i can not break through. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. next chapter. how did we end up this way?. se me nervously pulling at my clothes. and trying to look busy. and you are doing your best to avoid me. I am starting to think one day I will tell the story of us. how i was losing my mind when i saw you here. but you held your pride like you should have held me. oh. I am scared to see the ending. why are we pretending this is nothing?. I would tell you i miss you but i do not know how. I have never heard silence quite this loud. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. and i do not know what to say. since the twist of fate. when it all broke down. and the story of us looks a lot like a tragedy now. this is looking like a contest. of who can act like they care less. but i liked it better when you were on my side. the battles in your hands now. but i will lay my armor down. if you say you would rather love than fight. so many things that you wish i knew. but the story of us might be ending soon. now I am standing alone in a crowded room. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. but i do not know what to say. since the twist of fate. and it all broke down. and the story of us looks a lot like a tragedy now. now, now. and we are not speaking. and I am dying to know. is it killing you like it is killing me?. i do not know what to say. since the twist of fate. because we are going down. and the story of us looks a lot like a tragedy now. the end'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea967ad",
   "metadata": {},
   "source": [
    "I'm going to branch the pre-processing here at this point.  While there is still punctuation.  I think spaCy uses punctuation  for POS and I'm not sure NLTK does.  Want to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch genres_midcln_df.csv\n",
    "genres_df.to_csv('genres_midcln_df.csv', index= False)\n",
    "!aws s3 cp genres_midcln_df.csv s3://music-lyrics-chain/genres_midcln_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fbc4c",
   "metadata": {},
   "source": [
    "Remove punct, replace with a space. Remove stop letters 2 characters or less. Also, gensim tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9f734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 s, sys: 94.6 ms, total: 40.8 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(replace_punctuation)\n",
    "genres_df['lyrics'] =genres_df['lyrics'].apply(stops_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "618faa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think day tell story met sparks flew instantly people lucky ones know place spot searching room seat lately know page simple complication lead fallout things wish knew walls break standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy chapter end way nervously pulling clothes trying look busy best avoid starting think day tell story losing mind saw held pride like held scared ending pretending tell miss know heard silence loud standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy looking like contest act like care liked better battles hands lay armor love fight things wish knew story ending soon standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy speaking dying know killing like killing know twist fate going story looks lot like tragedy end'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d97cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>avg_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86391</td>\n",
       "      <td>86391</td>\n",
       "      <td>86391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>66856</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Intro</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>50</td>\n",
       "      <td>47408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.421444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.627203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song_name  genre     avg_words\n",
       "count      86391  86391  86391.000000\n",
       "unique     66856      6           NaN\n",
       "top        Intro   Rock           NaN\n",
       "freq          50  47408           NaN\n",
       "mean         NaN    NaN    108.421444\n",
       "std          NaN    NaN     74.627203\n",
       "min          NaN    NaN      0.000000\n",
       "25%          NaN    NaN     61.000000\n",
       "50%          NaN    NaN     88.000000\n",
       "75%          NaN    NaN    129.000000\n",
       "max          NaN    NaN   1380.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_count_df = genres_df.assign(avg_words=genres_df['lyrics'].str.split().str.len())\n",
    "g_cnt_df = pd.DataFrame((g_count_df), columns = ['song_name', 'genre', 'avg_words'])\n",
    "g_cnt_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3d1ac",
   "metadata": {},
   "source": [
    "The total number of words went down to 39% of the previous average.  Seems like A LOT.\n",
    "Decades dataset has a mean of 73 words.\n",
    "\n",
    "Below: genres_df, before function stops_letters:\n",
    "\n",
    "    song_name\tgenre\tavg_words\n",
    "    count\t86419\t86419\t86419.000000\n",
    "    unique\t66869\t6\tNaN\n",
    "    top\tIntro\tRock\tNaN\n",
    "    freq\t50\t47409\tNaN\n",
    "    mean\tNaN\tNaN\t274.471389\n",
    "        std\tNaN\tNaN\t168.492728\n",
    "        min\tNaN\tNaN\t1.000000\n",
    "        25%\tNaN\tNaN\t163.000000\n",
    "        50%\tNaN\tNaN\t232.000000\n",
    "        75%\tNaN\tNaN\t336.000000\n",
    "        max\tNaN\tNaN\t3301.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7297d78",
   "metadata": {},
   "source": [
    "Affinity Score - Sentiment Analysis.  This uses AFINN Lexicon, which is for microblogs (tweets).  This may not be the best sentiment lexicon for songs.  spaCy uses a different one.  Another reason to have a branch off of this trunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e07895ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "afinn = Afinn()\n",
    "\n",
    "def get_affinity_scores(lyrics):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    for t in lyrics:\n",
    "        if len(t) > 0:\n",
    "            scores.append(afinn.score(t) / len(t))\n",
    "        else:\n",
    "            count += 1\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abc24dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "new_affin = get_affinity_scores(genres_df['lyrics'].tolist())\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95bc5166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "genres_df['content_affin'] = new_affin\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch genres_main_affin_df.csv\n",
    "genres_df.to_csv('genres_main_affin_df.csv', index= False)\n",
    "!aws s3 cp genres_main_affin_df.csv s3://music-lyrics-chain/genres_main_affin_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc96fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>content_affin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>feel time way knowing fallen leaves night blow...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>days remember promise world warm feel know tru...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>lie mountain coal veins beds dig men axes dig ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly wet sand bench clothes stolen ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  feel time way knowing fallen leaves night blow...  ENGLISH  Rock   NaN   \n",
       "1  baby hold close try understand desire hunger b...  ENGLISH  Rock   NaN   \n",
       "2  days remember promise world warm feel know tru...  ENGLISH  Rock   NaN   \n",
       "3  lie mountain coal veins beds dig men axes dig ...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly wet sand bench clothes stolen ...  ENGLISH  Rock   NaN   \n",
       "\n",
       "   content_affin  \n",
       "0       0.041152  \n",
       "1      -0.006711  \n",
       "2       0.057047  \n",
       "3      -0.027473  \n",
       "4       0.009615  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c428e2a",
   "metadata": {},
   "source": [
    "Normalize Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f901ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "\n",
    "def lemmatized_word(text):\n",
    "\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return  \" \".join(lemmatized_word) #combine the words into a giant string that vectorizer can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b77707de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "genres_df['vector'] = genres_df['lyrics'].apply(lemmatized_word)\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75515628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>content_affin</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>feel time way knowing fallen leaves night blow...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>feel time way knowing fallen leaf night blowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>days remember promise world warm feel know tru...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057047</td>\n",
       "      <td>day remember promise world warm feel know true...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>lie mountain coal veins beds dig men axes dig ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>lie mountain coal vein bed dig men ax dig lie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>trudging slowly wet sand bench clothes stolen ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>trudging slowly wet sand bench clothes stolen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name                song_name  \\\n",
       "0   genres_csv  10000-maniacs           More Than This   \n",
       "1   genres_csv  10000-maniacs        Because The Night   \n",
       "2   genres_csv  10000-maniacs           These Are Days   \n",
       "3   genres_csv  10000-maniacs          A Campfire Song   \n",
       "4   genres_csv  10000-maniacs  Everyday Is Like Sunday   \n",
       "\n",
       "                                          link  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  feel time way knowing fallen leaves night blow...  ENGLISH  Rock   NaN   \n",
       "1  baby hold close try understand desire hunger b...  ENGLISH  Rock   NaN   \n",
       "2  days remember promise world warm feel know tru...  ENGLISH  Rock   NaN   \n",
       "3  lie mountain coal veins beds dig men axes dig ...  ENGLISH  Rock   NaN   \n",
       "4  trudging slowly wet sand bench clothes stolen ...  ENGLISH  Rock   NaN   \n",
       "\n",
       "   content_affin                                             vector  \n",
       "0       0.041152  feel time way knowing fallen leaf night blowin...  \n",
       "1      -0.006711  baby hold close try understand desire hunger b...  \n",
       "2       0.057047  day remember promise world warm feel know true...  \n",
       "3      -0.027473  lie mountain coal vein bed dig men ax dig lie ...  \n",
       "4       0.009615  trudging slowly wet sand bench clothes stolen ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "212fcf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think day tell story met sparks flew instantly people lucky ones know place spot searching room seat lately know page simple complication lead fallout things wish knew walls break standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy chapter end way nervously pulling clothes trying look busy best avoid starting think day tell story losing mind saw held pride like held scared ending pretending tell miss know heard silence loud standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy looking like contest act like care liked better battles hands lay armor love fight things wish knew story ending soon standing crowded room speaking dying know killing like killing know twist fate broke story looks lot like tragedy speaking dying know killing like killing know twist fate going story looks lot like tragedy end'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['lyrics']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d66d7fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think day tell story met spark flew instantly people lucky one know place spot searching room seat lately know page simple complication lead fallout thing wish knew wall break standing crowded room speaking dying know killing like killing know twist fate broke story look lot like tragedy chapter end way nervously pulling clothes trying look busy best avoid starting think day tell story losing mind saw held pride like held scared ending pretending tell miss know heard silence loud standing crowded room speaking dying know killing like killing know twist fate broke story look lot like tragedy looking like contest act like care liked better battle hand lay armor love fight thing wish knew story ending soon standing crowded room speaking dying know killing like killing know twist fate broke story look lot like tragedy speaking dying know killing like killing know twist fate going story look lot like tragedy end'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[84304]['vector']#genres Taylor Swift The Story of Us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85dddbd",
   "metadata": {},
   "source": [
    "What did this buy me, really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd2cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 6.85 ms, total: 1.29 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word counts\n",
    "genres_df['word_count'] = genres_df[\"lyrics\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "genres_df['character_count'] = genres_df[\"lyrics\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "genres_df['avg_word_length'] = genres_df['character_count'] / genres_df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f15eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!touch genres_affin_plus_df.csv\n",
    "genres_df.to_csv('genres_affin_plus_df.csv', index= False)\n",
    "!aws s3 cp genres_affin_plus_df.csv s3://music-lyrics-chain/genres_affin_plus_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887ddf2",
   "metadata": {},
   "source": [
    "Identify Sentiment, using affinity work from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e69089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_check (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    genres_df['sent_score'] = polarity_score\n",
    "    if polarity_score < 0:\n",
    "        return 'negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c3ce602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.3 s, sys: 78.8 ms, total: 39.4 s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "genres_df['sent_label'] = genres_df['lyrics'].apply(sentiment_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two additional cleanups.  Found during further EDA.  Remove tiny genres, remove three\n",
    "#songs that have NaN lyrics.\n",
    "\n",
    "genres_df.drop(genres_df[genres_df['genre']=='Samba'].index, inplace = True)\n",
    "genres_df.drop(genres_df[genres_df['genre']=='Sertanejo'].index, inplace = True)\n",
    "genres_df.drop(genres_df[genres_df['genre']=='Funk Carioca'].index, inplace = True)\n",
    "\n",
    "genres_df = genres_df.dropna(axis=0, subset=['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbbabe4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_csv</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>link</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>content_affin</th>\n",
       "      <th>vector</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>sent_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>feel time way knowing fallen leaves night blow...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>feel time way knowing fallen leaf night blowin...</td>\n",
       "      <td>42</td>\n",
       "      <td>202</td>\n",
       "      <td>4.809524</td>\n",
       "      <td>0.456061</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>baby hold close try understand desire hunger b...</td>\n",
       "      <td>93</td>\n",
       "      <td>504</td>\n",
       "      <td>5.419355</td>\n",
       "      <td>0.456061</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres_csv</td>\n",
       "      <td>10000-maniacs</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>days remember promise world warm feel know tru...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057047</td>\n",
       "      <td>day remember promise world warm feel know true...</td>\n",
       "      <td>49</td>\n",
       "      <td>250</td>\n",
       "      <td>5.102041</td>\n",
       "      <td>0.456061</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_csv    artist_name          song_name  \\\n",
       "0   genres_csv  10000-maniacs     More Than This   \n",
       "1   genres_csv  10000-maniacs  Because The Night   \n",
       "2   genres_csv  10000-maniacs     These Are Days   \n",
       "\n",
       "                                    link  \\\n",
       "0     /10000-maniacs/more-than-this.html   \n",
       "1  /10000-maniacs/because-the-night.html   \n",
       "2     /10000-maniacs/these-are-days.html   \n",
       "\n",
       "                                              lyrics language genre  date  \\\n",
       "0  feel time way knowing fallen leaves night blow...  ENGLISH  Rock   NaN   \n",
       "1  baby hold close try understand desire hunger b...  ENGLISH  Rock   NaN   \n",
       "2  days remember promise world warm feel know tru...  ENGLISH  Rock   NaN   \n",
       "\n",
       "   content_affin                                             vector  \\\n",
       "0       0.041152  feel time way knowing fallen leaf night blowin...   \n",
       "1      -0.006711  baby hold close try understand desire hunger b...   \n",
       "2       0.057047  day remember promise world warm feel know true...   \n",
       "\n",
       "   word_count  character_count  avg_word_length  sent_score sent_label  \n",
       "0          42              202         4.809524    0.456061   positive  \n",
       "1          93              504         5.419355    0.456061   positive  \n",
       "2          49              250         5.102041    0.456061   positive  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "318ef46c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86391 entries, 0 to 86390\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   original_csv     86391 non-null  object \n",
      " 1   artist_name      86391 non-null  object \n",
      " 2   song_name        86391 non-null  object \n",
      " 3   link             86391 non-null  object \n",
      " 4   lyrics           86391 non-null  object \n",
      " 5   language         86391 non-null  object \n",
      " 6   genre            86391 non-null  object \n",
      " 7   date             0 non-null      float64\n",
      " 8   content_affin    86391 non-null  float64\n",
      " 9   vector           86391 non-null  object \n",
      " 10  word_count       86391 non-null  int64  \n",
      " 11  character_count  86391 non-null  int64  \n",
      " 12  avg_word_length  86391 non-null  float64\n",
      " 13  sent_score       86391 non-null  float64\n",
      " 14  sent_label       86391 non-null  object \n",
      "dtypes: float64(4), int64(2), object(9)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "genres_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b6cd2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./genres_step_3_df.csv to s3://music-lyrics-chain/genres_step_3_df.csv\n",
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "!touch genres_step_3_df.csv\n",
    "genres_df.to_csv('genres_step_3_df.csv', index= False)\n",
    "!aws s3 cp genres_step_3_df.csv s3://music-lyrics-chain/genres_step_3_df.csv\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef72517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_csv                                              genres_csv\n",
       "artist_name                                             taylor-swift\n",
       "song_name                                            The Story Of Us\n",
       "link                              /taylor-swift/the-story-of-us.html\n",
       "lyrics             think day tell story met sparks flew instantly...\n",
       "language                                                     ENGLISH\n",
       "genre                                                            Pop\n",
       "date                                                             NaN\n",
       "content_affin                                              -0.022556\n",
       "vector             think day tell story met spark flew instantly ...\n",
       "word_count                                                       151\n",
       "character_count                                                  781\n",
       "avg_word_length                                             5.172185\n",
       "sent_score                                                  0.456061\n",
       "sent_label                                                  positive\n",
       "Name: 84304, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.loc[84304]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
