{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fb03cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/Gretzky/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import traceback\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "# Ignore warnings from scikit-learn to make this notebook a bit nicer\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\", leave=False)\n",
    "import string\n",
    "\n",
    "import unicodedata  # might need to pip install unicodedate2 on aws sagemaker\n",
    "import contractions\n",
    "from contractions import contractions_dict ## pip installed this\n",
    "from wordcloud import WordCloud, STOPWORDS #pip install\n",
    "from textblob import TextBlob\n",
    "!python -m textblob.download_corpora\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import resample # Covert too much Rock! to just enough\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2',rc={'figure.figsize':(9,6),'figure.dpi':90})\n",
    "\n",
    "# Increase screen size.\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2', rc={'figure.figsize':(9,6), 'figure.dpi':100})\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "\n",
    "# Visual analysis of model performance\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.classifier import classification_report\n",
    "from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "#Pipeline toolset\n",
    "# Used to divide our dataseets into train/test splits\n",
    "# Data will be randomly shuffled so running this notebook multiple times may lead to different results\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Model toolset\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Evaluation toolset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import FeatureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2fead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "def aws_session(region_name='us-east-1'):\n",
    "    return boto3.session.Session(aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'), #looks for any .env file\n",
    "                                aws_secret_access_key=os.getenv('AWS_ACCESS_KEY_SECRET'), #Has to be in same directory\n",
    "                                region_name=region_name) #from above\n",
    "\n",
    "def make_bucket(name, acl): \n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    return s3_resource.create_bucket(Bucket=name, ACL=acl)\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, file_path):\n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    file_dir, file_name = os.path.split(file_path)\n",
    "\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    bucket.upload_file(\n",
    "      Filename=file_path,\n",
    "      Key=file_name,\n",
    "      ExtraArgs={'ACL': 'private'}\n",
    "    )\n",
    "\n",
    "    s3_url = f\"https://{bucket_name}.s3.amazonaws.com/{file_name}\"\n",
    "    return s3_url\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False,key='###',secret='###')\n",
    "\n",
    "g_df = pd.read_csv('g2_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1e990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop first, useless column.\n",
    "g_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df41b138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86290 entries, 0 to 86289\n",
      "Data columns (total 36 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   genre                   86290 non-null  object \n",
      " 1   song_name               86290 non-null  object \n",
      " 2   lyrics                  86290 non-null  object \n",
      " 3   full_word_count         86290 non-null  int64  \n",
      " 4   full_character_count    86290 non-null  int64  \n",
      " 5   full_avg_word_length    86290 non-null  float64\n",
      " 6   med_lyrics              86290 non-null  object \n",
      " 7   med_word_count          86290 non-null  int64  \n",
      " 8   med_character_count     86290 non-null  int64  \n",
      " 9   med_avg_word_length     86290 non-null  float64\n",
      " 10  med_content_affin       86290 non-null  float64\n",
      " 11  med_sent_label          86290 non-null  object \n",
      " 12  med_sent_score          86290 non-null  float64\n",
      " 13  med_vector              86290 non-null  object \n",
      " 14  med_rock_genre_count    86290 non-null  float64\n",
      " 15  med_rock_bool           86290 non-null  int64  \n",
      " 16  med_hiphop_genre_count  86290 non-null  float64\n",
      " 17  med_hiphop_bool         86290 non-null  int64  \n",
      " 18  med_pop_genre_count     86290 non-null  float64\n",
      " 19  med_pop_bool            86290 non-null  int64  \n",
      " 20  med_genre_count         86290 non-null  float64\n",
      " 21  sml_lyrics              86290 non-null  object \n",
      " 22  sml_word_count          86290 non-null  int64  \n",
      " 23  sml_character_count     86290 non-null  int64  \n",
      " 24  sml_avg_word_length     86290 non-null  float64\n",
      " 25  sml_content_affin       86290 non-null  float64\n",
      " 26  sml_sent_label          86290 non-null  object \n",
      " 27  sml_sent_score          86290 non-null  float64\n",
      " 28  sml_vector              86290 non-null  object \n",
      " 29  sml_rock_genre_count    86290 non-null  float64\n",
      " 30  sml_rock_bool           86290 non-null  int64  \n",
      " 31  sml_hiphop_genre_count  86290 non-null  float64\n",
      " 32  sml_hiphop_bool         86290 non-null  int64  \n",
      " 33  sml_pop_genre_count     86290 non-null  float64\n",
      " 34  sml_pop_bool            86290 non-null  int64  \n",
      " 35  sml_genre_count         86290 non-null  float64\n",
      "dtypes: float64(15), int64(12), object(9)\n",
      "memory usage: 23.7+ MB\n"
     ]
    }
   ],
   "source": [
    "g_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d5c1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>full_word_count</th>\n",
       "      <th>full_character_count</th>\n",
       "      <th>full_avg_word_length</th>\n",
       "      <th>med_lyrics</th>\n",
       "      <th>med_word_count</th>\n",
       "      <th>med_character_count</th>\n",
       "      <th>med_avg_word_length</th>\n",
       "      <th>med_content_affin</th>\n",
       "      <th>med_sent_label</th>\n",
       "      <th>med_sent_score</th>\n",
       "      <th>med_vector</th>\n",
       "      <th>med_rock_genre_count</th>\n",
       "      <th>med_rock_bool</th>\n",
       "      <th>med_hiphop_genre_count</th>\n",
       "      <th>med_hiphop_bool</th>\n",
       "      <th>med_pop_genre_count</th>\n",
       "      <th>med_pop_bool</th>\n",
       "      <th>med_genre_count</th>\n",
       "      <th>sml_lyrics</th>\n",
       "      <th>sml_word_count</th>\n",
       "      <th>sml_character_count</th>\n",
       "      <th>sml_avg_word_length</th>\n",
       "      <th>sml_content_affin</th>\n",
       "      <th>sml_sent_label</th>\n",
       "      <th>sml_sent_score</th>\n",
       "      <th>sml_vector</th>\n",
       "      <th>sml_rock_genre_count</th>\n",
       "      <th>sml_rock_bool</th>\n",
       "      <th>sml_hiphop_genre_count</th>\n",
       "      <th>sml_hiphop_bool</th>\n",
       "      <th>sml_pop_genre_count</th>\n",
       "      <th>sml_pop_bool</th>\n",
       "      <th>sml_genre_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>66799</td>\n",
       "      <td>86203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Rock</td>\n",
       "      <td>Intro</td>\n",
       "      <td>so  so you think you can tell  heaven from hel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merry little christmas let heart light trouble...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaming white christmas like one know treetop...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaming white christmas like ones know gliste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feel like home feel like feel like young feel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>47406</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355.093638</td>\n",
       "      <td>1067.958303</td>\n",
       "      <td>3.032924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.455858</td>\n",
       "      <td>552.463715</td>\n",
       "      <td>5.120146</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.224591</td>\n",
       "      <td>91.105574</td>\n",
       "      <td>0.162128</td>\n",
       "      <td>0.358106</td>\n",
       "      <td>0.099977</td>\n",
       "      <td>91.470013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.333666</td>\n",
       "      <td>509.263924</td>\n",
       "      <td>5.011926</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>5.672731</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>5.687131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.656149</td>\n",
       "      <td>651.998326</td>\n",
       "      <td>0.300625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.646193</td>\n",
       "      <td>379.487446</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.417315</td>\n",
       "      <td>351.449939</td>\n",
       "      <td>0.368570</td>\n",
       "      <td>3.012329</td>\n",
       "      <td>0.299971</td>\n",
       "      <td>351.424018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.819909</td>\n",
       "      <td>338.198070</td>\n",
       "      <td>0.429539</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.099676</td>\n",
       "      <td>110.012447</td>\n",
       "      <td>0.133194</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>110.014459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.493151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.503979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>638.000000</td>\n",
       "      <td>2.853833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>-0.012953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>908.000000</td>\n",
       "      <td>3.026846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>4.982759</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>1303.000000</td>\n",
       "      <td>3.206452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>5.256850</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4723.000000</td>\n",
       "      <td>13407.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>7212.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.462428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1278.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17700.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17700.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre song_name                                             lyrics  full_word_count  full_character_count  full_avg_word_length                                         med_lyrics  med_word_count  med_character_count  med_avg_word_length  med_content_affin med_sent_label  med_sent_score                                         med_vector  med_rock_genre_count  med_rock_bool  med_hiphop_genre_count  med_hiphop_bool  med_pop_genre_count  med_pop_bool  med_genre_count                                         sml_lyrics  sml_word_count  sml_character_count  sml_avg_word_length  sml_content_affin sml_sent_label  sml_sent_score                                         sml_vector  sml_rock_genre_count  sml_rock_bool  sml_hiphop_genre_count  sml_hiphop_bool  sml_pop_genre_count  sml_pop_bool  sml_genre_count\n",
       "count   86290     86290                                              86290     86290.000000          86290.000000          86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290    86290.000000                                              86290          86290.000000   86290.000000            86290.000000     86290.000000         86290.000000  86290.000000     86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290    86290.000000                                              86290          86290.000000   86290.000000            86290.000000     86290.000000         86290.000000  86290.000000     86290.000000\n",
       "unique      3     66799                                              86203              NaN                   NaN                   NaN                                              85378             NaN                  NaN                  NaN                NaN              3             NaN                                              85355                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN                                              85286             NaN                  NaN                  NaN                NaN              3             NaN                                              85264                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "top      Rock     Intro  so  so you think you can tell  heaven from hel...              NaN                   NaN                   NaN  merry little christmas let heart light trouble...             NaN                  NaN                  NaN                NaN       positive             NaN  dreaming white christmas like one know treetop...                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN  dreaming white christmas like ones know gliste...             NaN                  NaN                  NaN                NaN       positive             NaN  feel like home feel like feel like young feel ...                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "freq    47406        50                                                  3              NaN                   NaN                   NaN                                                  4             NaN                  NaN                  NaN                NaN          58208             NaN                                                  4                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN                                                  4             NaN                  NaN                  NaN                NaN          58255             NaN                                                  4                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "mean      NaN       NaN                                                NaN       355.093638           1067.958303              3.032924                                                NaN      108.455858           552.463715             5.120146           0.010880            NaN        0.096838                                                NaN              0.006332       0.224591               91.105574         0.162128             0.358106      0.099977        91.470013                                                NaN      102.333666           509.263924             5.011926           0.011444            NaN        0.097358                                                NaN              0.000238       0.010036                5.672731         0.018067             0.014162      0.000568         5.687131\n",
       "std       NaN       NaN                                                NaN       218.656149            651.998326              0.300625                                                NaN       74.646193           379.487446             0.467359           0.046185            NaN        0.213209                                                NaN              0.021912       0.417315              351.449939         0.368570             3.012329      0.299971       351.424018                                                NaN       68.819909           338.198070             0.429539           0.048637            NaN        0.213692                                                NaN              0.006379       0.099676              110.012447         0.133194             0.774038      0.023823       110.014459\n",
       "min       NaN       NaN                                                NaN         1.000000              8.000000              0.051852                                                NaN        1.000000             4.000000             3.000000          -0.493151            NaN       -1.000000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN        1.000000             4.000000             3.000000          -0.503979            NaN       -1.000000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "25%       NaN       NaN                                                NaN       209.000000            638.000000              2.853833                                                NaN       61.000000           312.000000             4.812500          -0.012953            NaN       -0.035000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN       58.000000           291.000000             4.733333          -0.013661            NaN       -0.034707                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "50%       NaN       NaN                                                NaN       299.000000            908.000000              3.026846                                                NaN       88.000000           450.000000             5.083333           0.008451            NaN        0.092857                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN       84.000000           421.000000             4.982759           0.009302            NaN        0.093636                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "75%       NaN       NaN                                                NaN       436.000000           1303.000000              3.206452                                                NaN      129.000000           661.000000             5.384615           0.032754            NaN        0.234662                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.120000                                                NaN      123.000000           615.000000             5.256850           0.034800            NaN        0.235714                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "max       NaN       NaN                                                NaN      4723.000000          13407.000000              9.000000                                                NaN     1380.000000          7212.000000            12.000000           0.462428            NaN        1.000000                                                NaN              0.970000       1.000000            18100.000000         1.000000           197.000000      1.000000     18100.000000                                                NaN     1278.000000          6486.000000            12.000000           0.500000            NaN        1.000000                                                NaN              0.660000       1.000000            17700.000000         1.000000            91.000000      1.000000     17700.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e4c9b",
   "metadata": {},
   "source": [
    "Code to normalize / standardize / MinMax various numeric columns, as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfac0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling various counts.\n",
    "# Leaving sent_score (-1 to +1, already), content_affin (-.5 to .5, already), genre_bool (0 or 1, already)\n",
    "# and avg_word_length (no outliers) alone. \n",
    "#Will be dropping [size]_genre_count, (was never a good idea).\n",
    "# I am doing it now, vice in the pipeline, because I am not doing the same thing to all Float64 d.types()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "column_to_normalize = ['full_word_count','full_character_count',\n",
    "                       'med_word_count','med_character_count',\n",
    "                       'med_rock_genre_count','med_hiphop_genre_count','med_pop_genre_count',\n",
    "                       'sml_word_count','sml_character_count',\n",
    "                       'sml_rock_genre_count','sml_hiphop_genre_count','sml_pop_genre_count']\n",
    "\n",
    "# \"Scaled_DataFrame\" \n",
    "s_df = g_df.copy()\n",
    "s2_df = pd.DataFrame((s_df), columns = column_to_normalize)\n",
    "\n",
    "\n",
    "x = s2_df.values\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns = column_to_normalize, index = s_df.index)\n",
    "\n",
    "s_df[column_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16509b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>full_word_count</th>\n",
       "      <th>full_character_count</th>\n",
       "      <th>full_avg_word_length</th>\n",
       "      <th>med_lyrics</th>\n",
       "      <th>med_word_count</th>\n",
       "      <th>med_character_count</th>\n",
       "      <th>med_avg_word_length</th>\n",
       "      <th>med_content_affin</th>\n",
       "      <th>med_sent_label</th>\n",
       "      <th>med_sent_score</th>\n",
       "      <th>med_vector</th>\n",
       "      <th>med_rock_genre_count</th>\n",
       "      <th>med_rock_bool</th>\n",
       "      <th>med_hiphop_genre_count</th>\n",
       "      <th>med_hiphop_bool</th>\n",
       "      <th>med_pop_genre_count</th>\n",
       "      <th>med_pop_bool</th>\n",
       "      <th>med_genre_count</th>\n",
       "      <th>sml_lyrics</th>\n",
       "      <th>sml_word_count</th>\n",
       "      <th>sml_character_count</th>\n",
       "      <th>sml_avg_word_length</th>\n",
       "      <th>sml_content_affin</th>\n",
       "      <th>sml_sent_label</th>\n",
       "      <th>sml_sent_score</th>\n",
       "      <th>sml_vector</th>\n",
       "      <th>sml_rock_genre_count</th>\n",
       "      <th>sml_rock_bool</th>\n",
       "      <th>sml_hiphop_genre_count</th>\n",
       "      <th>sml_hiphop_bool</th>\n",
       "      <th>sml_pop_genre_count</th>\n",
       "      <th>sml_pop_bool</th>\n",
       "      <th>sml_genre_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "      <td>86290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>66799</td>\n",
       "      <td>86203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Rock</td>\n",
       "      <td>Intro</td>\n",
       "      <td>so  so you think you can tell  heaven from hel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merry little christmas let heart light trouble...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaming white christmas like one know treetop...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaming white christmas like ones know gliste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feel like home feel like feel like young feel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>47406</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>3.032924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077923</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>5.120146</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.224591</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.162128</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.099977</td>\n",
       "      <td>91.470013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079353</td>\n",
       "      <td>0.077949</td>\n",
       "      <td>5.011926</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>5.687131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046306</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.300625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.052648</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.417315</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.368570</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.299971</td>\n",
       "      <td>351.424018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.052175</td>\n",
       "      <td>0.429539</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.099676</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.133194</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>110.014459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.493151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.503979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>0.047018</td>\n",
       "      <td>2.853833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.042730</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>-0.012953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.044276</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>3.026846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>0.064332</td>\n",
       "      <td>4.982759</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092122</td>\n",
       "      <td>0.096649</td>\n",
       "      <td>3.206452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095536</td>\n",
       "      <td>0.094261</td>\n",
       "      <td>5.256850</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.462428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17700.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre song_name                                             lyrics  full_word_count  full_character_count  full_avg_word_length                                         med_lyrics  med_word_count  med_character_count  med_avg_word_length  med_content_affin med_sent_label  med_sent_score                                         med_vector  med_rock_genre_count  med_rock_bool  med_hiphop_genre_count  med_hiphop_bool  med_pop_genre_count  med_pop_bool  med_genre_count                                         sml_lyrics  sml_word_count  sml_character_count  sml_avg_word_length  sml_content_affin sml_sent_label  sml_sent_score                                         sml_vector  sml_rock_genre_count  sml_rock_bool  sml_hiphop_genre_count  sml_hiphop_bool  sml_pop_genre_count  sml_pop_bool  sml_genre_count\n",
       "count   86290     86290                                              86290     86290.000000          86290.000000          86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290    86290.000000                                              86290          86290.000000   86290.000000            86290.000000     86290.000000         86290.000000  86290.000000     86290.000000                                              86290    86290.000000         86290.000000         86290.000000       86290.000000          86290    86290.000000                                              86290          86290.000000   86290.000000            86290.000000     86290.000000         86290.000000  86290.000000     86290.000000\n",
       "unique      3     66799                                              86203              NaN                   NaN                   NaN                                              85378             NaN                  NaN                  NaN                NaN              3             NaN                                              85355                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN                                              85286             NaN                  NaN                  NaN                NaN              3             NaN                                              85264                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "top      Rock     Intro  so  so you think you can tell  heaven from hel...              NaN                   NaN                   NaN  merry little christmas let heart light trouble...             NaN                  NaN                  NaN                NaN       positive             NaN  dreaming white christmas like one know treetop...                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN  dreaming white christmas like ones know gliste...             NaN                  NaN                  NaN                NaN       positive             NaN  feel like home feel like feel like young feel ...                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "freq    47406        50                                                  3              NaN                   NaN                   NaN                                                  4             NaN                  NaN                  NaN                NaN          58208             NaN                                                  4                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN                                                  4             NaN                  NaN                  NaN                NaN          58255             NaN                                                  4                   NaN            NaN                     NaN              NaN                  NaN           NaN              NaN\n",
       "mean      NaN       NaN                                                NaN         0.074988              0.079107              3.032924                                                NaN        0.077923             0.076091             5.120146           0.010880            NaN        0.096838                                                NaN              0.006528       0.224591                0.005033         0.162128             0.001818      0.099977        91.470013                                                NaN        0.079353             0.077949             5.011926           0.011444            NaN        0.097358                                                NaN              0.000361       0.010036                0.000320         0.018067             0.000156      0.000568         5.687131\n",
       "std       NaN       NaN                                                NaN         0.046306              0.048660              0.300625                                                NaN        0.054131             0.052648             0.467359           0.046185            NaN        0.213209                                                NaN              0.022590       0.417315                0.019417         0.368570             0.015291      0.299971       351.424018                                                NaN        0.053892             0.052175             0.429539           0.048637            NaN        0.213692                                                NaN              0.009666       0.099676                0.006215         0.133194             0.008506      0.023823       110.014459\n",
       "min       NaN       NaN                                                NaN         0.000000              0.000000              0.051852                                                NaN        0.000000             0.000000             3.000000          -0.493151            NaN       -1.000000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN        0.000000             0.000000             3.000000          -0.503979            NaN       -1.000000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "25%       NaN       NaN                                                NaN         0.044049              0.047018              2.853833                                                NaN        0.043510             0.042730             4.812500          -0.012953            NaN       -0.035000                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN        0.044636             0.044276             4.733333          -0.013661            NaN       -0.034707                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "50%       NaN       NaN                                                NaN         0.063109              0.067169              3.026846                                                NaN        0.063089             0.061876             5.083333           0.008451            NaN        0.092857                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000                                                NaN        0.064996             0.064332             4.982759           0.009302            NaN        0.093636                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "75%       NaN       NaN                                                NaN         0.092122              0.096649              3.206452                                                NaN        0.092821             0.091149             5.384615           0.032754            NaN        0.234662                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.120000                                                NaN        0.095536             0.094261             5.256850           0.034800            NaN        0.235714                                                NaN              0.000000       0.000000                0.000000         0.000000             0.000000      0.000000         0.000000\n",
       "max       NaN       NaN                                                NaN         1.000000              1.000000              9.000000                                                NaN        1.000000             1.000000            12.000000           0.462428            NaN        1.000000                                                NaN              1.000000       1.000000                1.000000         1.000000             1.000000      1.000000     18100.000000                                                NaN        1.000000             1.000000            12.000000           0.500000            NaN        1.000000                                                NaN              1.000000       1.000000                1.000000         1.000000             1.000000      1.000000     17700.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ffc454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86290 entries, 0 to 86289\n",
      "Data columns (total 36 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   genre                   86290 non-null  object \n",
      " 1   song_name               86290 non-null  object \n",
      " 2   lyrics                  86290 non-null  object \n",
      " 3   full_word_count         86290 non-null  float64\n",
      " 4   full_character_count    86290 non-null  float64\n",
      " 5   full_avg_word_length    86290 non-null  float64\n",
      " 6   med_lyrics              86290 non-null  object \n",
      " 7   med_word_count          86290 non-null  float64\n",
      " 8   med_character_count     86290 non-null  float64\n",
      " 9   med_avg_word_length     86290 non-null  float64\n",
      " 10  med_content_affin       86290 non-null  float64\n",
      " 11  med_sent_label          86290 non-null  object \n",
      " 12  med_sent_score          86290 non-null  float64\n",
      " 13  med_vector              86290 non-null  object \n",
      " 14  med_rock_genre_count    86290 non-null  float64\n",
      " 15  med_rock_bool           86290 non-null  int64  \n",
      " 16  med_hiphop_genre_count  86290 non-null  float64\n",
      " 17  med_hiphop_bool         86290 non-null  int64  \n",
      " 18  med_pop_genre_count     86290 non-null  float64\n",
      " 19  med_pop_bool            86290 non-null  int64  \n",
      " 20  med_genre_count         86290 non-null  float64\n",
      " 21  sml_lyrics              86290 non-null  object \n",
      " 22  sml_word_count          86290 non-null  float64\n",
      " 23  sml_character_count     86290 non-null  float64\n",
      " 24  sml_avg_word_length     86290 non-null  float64\n",
      " 25  sml_content_affin       86290 non-null  float64\n",
      " 26  sml_sent_label          86290 non-null  object \n",
      " 27  sml_sent_score          86290 non-null  float64\n",
      " 28  sml_vector              86290 non-null  object \n",
      " 29  sml_rock_genre_count    86290 non-null  float64\n",
      " 30  sml_rock_bool           86290 non-null  int64  \n",
      " 31  sml_hiphop_genre_count  86290 non-null  float64\n",
      " 32  sml_hiphop_bool         86290 non-null  int64  \n",
      " 33  sml_pop_genre_count     86290 non-null  float64\n",
      " 34  sml_pop_bool            86290 non-null  int64  \n",
      " 35  sml_genre_count         86290 non-null  float64\n",
      "dtypes: float64(21), int64(6), object(9)\n",
      "memory usage: 23.7+ MB\n"
     ]
    }
   ],
   "source": [
    "s_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f884a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision on what features to include, borne of EDA and visual steering.\n",
    "\n",
    "df = pd.DataFrame((s_df), columns=['genre','full_word_count','full_character_count',\n",
    "                                  'med_rock_bool','med_hiphop_bool','med_pop_bool',\n",
    "                                  'sml_word_count','sml_character_count',\n",
    "                                   'sml_sent_label','sml_sent_score','sml_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57b4d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre                       0\n",
       "full_word_count             1\n",
       "full_character_count        2\n",
       "med_rock_bool           66910\n",
       "med_hiphop_bool         72300\n",
       "med_pop_bool            77663\n",
       "sml_word_count             16\n",
       "sml_character_count         3\n",
       "sml_sent_label              0\n",
       "sml_sent_score           1473\n",
       "sml_vector                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick code to count the counts, so to speak.\n",
    "#Returns a .info() looking print with the number of '0' in each column.  Subtracting\n",
    "#that from total number gives the number of med_pop/rock/hiphop_scores that there are.\n",
    "df[df == 0].count(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fb648",
   "metadata": {},
   "source": [
    "Code to downsample and set up test train splits. \n",
    "Your df may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbc510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hip Hop    13560\n",
       "Pop        13560\n",
       "Rock       13560\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 99\n",
    "\n",
    "#Separate majority and minority classes, twice.\n",
    "majority = df[df.genre=='Rock']\n",
    "minority = df[df.genre=='Hip Hop']\n",
    "\n",
    "# Downsample majority class\n",
    "majority_rock_downsampled = resample(majority, \n",
    "                                replace=False, # sample without replacement\n",
    "                                n_samples=len(minority), # to match minority class\n",
    "                                random_state=seed) # reproducible results\n",
    "\n",
    "seed = 99\n",
    "\n",
    "#Separate majority and minority classes, again.\n",
    "majority = df[df.genre=='Pop']\n",
    "minority = df[df.genre=='Hip Hop']\n",
    "\n",
    "# Downsample majority class\n",
    "majority_pop_downsampled = resample(majority, \n",
    "                                replace=False, # sample without replacement\n",
    "                                n_samples=len(minority), # to match minority class\n",
    "                                random_state=seed) # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "dfd = pd.concat([majority_rock_downsampled, majority_pop_downsampled, minority])\n",
    "\n",
    "# Display new class counts\n",
    "dfd['genre'].value_counts()\n",
    "# dfd = 'data frame downsampled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d3604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a small df to use to get the pipeline working...\n",
    "s_dfd = dfd.sample(frac=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b40ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8136 entries, 59095 to 7801\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   genre                 8136 non-null   object \n",
      " 1   full_word_count       8136 non-null   float64\n",
      " 2   full_character_count  8136 non-null   float64\n",
      " 3   med_rock_bool         8136 non-null   int64  \n",
      " 4   med_hiphop_bool       8136 non-null   int64  \n",
      " 5   med_pop_bool          8136 non-null   int64  \n",
      " 6   sml_word_count        8136 non-null   float64\n",
      " 7   sml_character_count   8136 non-null   float64\n",
      " 8   sml_sent_label        8136 non-null   object \n",
      " 9   sml_sent_score        8136 non-null   float64\n",
      " 10  sml_vector            8136 non-null   object \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 762.8+ KB\n"
     ]
    }
   ],
   "source": [
    "s_dfd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4295c57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock       2719\n",
       "Pop        2717\n",
       "Hip Hop    2700\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_dfd.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb03b367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5465\n",
       "negative    2550\n",
       "neutral      121\n",
       "Name: sml_sent_label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_dfd.sml_sent_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y.  Obviously, your df name may vary...\n",
    "X = s_dfd.loc[ : , dfd.columns != 'genre']\n",
    "y = s_dfd['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349216e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 10) (6508,)\n",
      "(1628, 10) (1628,)\n"
     ]
    }
   ],
   "source": [
    "# tts.\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf279b4",
   "metadata": {},
   "source": [
    "This is the pipeline code that worked, just.  \n",
    "\n",
    "Issues:\n",
    "1) visualize_model function tests on the same data that it trained upon.  Bagging classifiers overfit.\n",
    "2) lst_label, cat_label.  Same thing, called differently in functions.\n",
    "3) tf-IDF added\n",
    "4) one hot encoding of sent_label.\n",
    "5) has an imputer, don't need it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d94cee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make label lists\n",
    "cat_labels = list(set(s_dfd['genre']))\n",
    "label_lst = list(set(s_dfd['genre']))\n",
    "sent_label = ['positive','negative','neutral'] #It hates this, for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "546f5e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-a376631021b8>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-a376631021b8>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    ]), remainder='drop'),\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Merging pipeline, columntransformer and feature union...breaking everywhere...\n",
    "\n",
    "categorical = make_column_selector(pattern='sml_sent_label')\n",
    "numeric = make_column_selector(pattern='sml_sent_score')\n",
    "vector = make_column_selector(pattern='sml_vector')\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('ordinal', OrdinalEncoder(categories = 'auto', handle_unknown='use_encoded_value', \n",
    "                                  unknown_value=-1), categorical),\n",
    "        ('scalar', MinMaxScaler(feature_range=(0,2)), numeric),\n",
    "        ('tfidf', FeatureUnion([\n",
    "            ('vectorize', Pipeline([\n",
    "                ('counts', CountVectorizer(), vector),\n",
    "                ('finally', TfidfTransformer(),vector)\n",
    "            ])),\n",
    "    ]), remainder='drop'),\n",
    "    ], remainder='passthrough'))    \n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "viz = ClassificationReport(model, is_fitted = True)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3747173d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'midnight sky shining face feel wave embracing peace mind time tide wait wait yeah hate love trying reality dream hate love afraid need like hate love hate love faded photograph picture perfect love locked inside frame forgiving truth trust betrayed time heals left left hate love trying reality dream hate love afraid need like hate love hate love loneliness innocence heart learned hate truth love tearing apart hate love trying reality dream hate love afraid need like hate love hate love'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-9d0ff0ab7c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m ])\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mviz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mover\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \"\"\"\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_parallel_func\u001b[0;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mtransformers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         return Parallel(n_jobs=self.n_jobs)(delayed(func)(\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FeatureUnion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    433\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 delayed(func)(\n\u001b[1;32m    437\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mof\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \"\"\"\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'midnight sky shining face feel wave embracing peace mind time tide wait wait yeah hate love trying reality dream hate love afraid need like hate love hate love faded photograph picture perfect love locked inside frame forgiving truth trust betrayed time heals left left hate love trying reality dream hate love afraid need like hate love hate love loneliness innocence heart learned hate truth love tearing apart hate love trying reality dream hate love afraid need like hate love hate love'"
     ]
    }
   ],
   "source": [
    "categorical = make_column_selector(pattern='sml_sent_label')\n",
    "numeric = make_column_selector(pattern='sml_sent_score')\n",
    "vector = make_column_selector(pattern='sml_vector')\n",
    "\n",
    "model = Pipeline([\n",
    "    ('tfidf', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('vectorize', Pipeline([\n",
    "                ('columns_1', ColumnTransformer([\n",
    "                ('counts', CountVectorizer(), vector),\n",
    "                ('finally', TfidfTransformer(),vector),\n",
    "                ('really', TruncatedSVD(n_components=5, n_iter=7, random_state=42), vector),\n",
    "            ], remainder='drop')\n",
    "            )])),\n",
    "        ('columns_2', ColumnTransformer([\n",
    "        ('label', OrdinalEncoder(categories='auto', handle_unknown='use_encoded_value', \n",
    "                                  unknown_value=-1), categorical),\n",
    "        ('scalar', MinMaxScaler(feature_range=(0,2)), numeric),\n",
    "        ('skip_it', OrdinalEncoder(categories = 'auto', handle_unknown='use_encoded_value', \n",
    "                                   unknown_value=-1), vector)\n",
    "    ], remainder='passthrough'))\n",
    "    ],\n",
    "        transformer_weights= {\n",
    "            'vectorize': 0.2,\n",
    "            'columns_2': 0.8,\n",
    "        }\n",
    "    )),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "viz = ClassificationReport(model, is_fitted = True)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79692d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tupac death row motherfucker dear mama caught sickness robbed slipped left witness wonder catch snitch shoot rich want commit murder damn got trapped walkin talkin kind win life wheel fortune chance spin got time cop trip try catch fuckin trigger happy let sucker snatch niggaz gettin jealous jealous tryin stash whip dive pump as peter picked pepper pick punk snatched like threw trunk punk thought bluffin swear nothin nice life wrestle mics listen scream tray deee went insane guess little finally brain new pull sentenced pen remember little bird told friend trouble mind old fiveoh blaow blaow turn fortyniners chorus eminem gone carry mourn rejoice time hear sound voice know lookin smilin feel thing baby feel pain smile tupac dear mama cop understand turned life crime came broken family uncle touch told scared hold kept deep inside let fuel anger homies mercy stranger brother cell hard black trapped livin hell shouldnta let catch instead livin sad jail coulda died free happy raped norm passed hear asshole gettin torn animal sleep instead countin sheep niggaz countin pen turn old cold soul best friend mama prayed tell lord way prepare day come death breath trick lose hope buddy hangin dead rope death row chorus eminem gone carry mourn rejoice time hear sound voice know lookin smilin feel thing baby feel pain smile tupac dear mama sentenced death final day countin breath bitter dyin seen know dreamed baby dead got beef sick society quick goodbye tell preacher crook book cared sure drop dime god bout crime poor people judge peer year love got man big plan state pen homies motherfucker steer clear motherfucker got locked got trapped better gettin shot convinced selfdefense way stay strapped pack gat day wish known straight headin chair chorus eminem gone carry mourn rejoice time hear sound voice know lookin smilin feel thing baby feel pain smile'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]['sml_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b472eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base pipeline, and first F1 score.\n",
    "\n",
    "categorical = make_column_selector(pattern='sml_sent_label')\n",
    "numeric = make_column_selector(pattern='sml_sent_score')\n",
    "vector = make_column_selector(pattern='sml_vector')\n",
    "\n",
    "models = [\n",
    "    SVC(gamma='auto'), NuSVC(gamma='auto'), LinearSVC(),\n",
    "    SGDClassifier(max_iter=100, tol=1e-3), KNeighborsClassifier(),\n",
    "    LogisticRegression(solver='lbfgs'), LogisticRegressionCV(cv=3),\n",
    "    BaggingClassifier(), ExtraTreesClassifier(n_estimators=300),\n",
    "    RandomForestClassifier(n_estimators=300)\n",
    "]\n",
    "\n",
    "\n",
    "def score_model(X, y, estimator, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        ('ordinal', OrdinalEncoder(categories = sent_label, handle_unknown='use_encoded_value', \n",
    "                                  unknown_value=10), categorical),\n",
    "        ('scalar', MinMaxScaler(feature_range=(0,2)), numeric),\n",
    "        ('tfidf', TfidfTransformer(),vector),\n",
    "    ], remainder='passthrough')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "     )])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    model.fit(X, y, **kwargs)\n",
    "\n",
    "    expected  = y\n",
    "    predicted = model.predict(X)\n",
    "\n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"F1 SCORE {}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted,average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "921a9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma='auto') Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "NuSVC(gamma='auto') Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "LinearSVC() Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "SGDClassifier(max_iter=100) Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "KNeighborsClassifier() Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "LogisticRegression() Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "LogisticRegressionCV(cv=3) Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "BaggingClassifier() Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "ExtraTreesClassifier(n_estimators=300) Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n",
      "RandomForestClassifier(n_estimators=300) Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-639f895201b5>\", line 3, in <module>\n",
      "    score_model(X, y, model)\n",
      "  File \"<ipython-input-29-05a4600a6ded>\", line 21, in score_model\n",
      "    model = Pipeline([\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 118, in __init__\n",
      "    self._validate_steps()\n",
      "  File \"/opt/anaconda3/envs/lyricsenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 154, in _validate_steps\n",
      "    names, estimators = zip(*self.steps)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      " too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        score_model(X, y, model)\n",
    "        #visualize_model(X, y, model,cat_labels)\n",
    "        #a_visualize_model(X, y, model,cat_labels)\n",
    "        #conf_matrix(X, y, model,cat_labels)\n",
    "    except Exception as exc:\n",
    "        print(model, traceback.format_exc(), exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b55a09",
   "metadata": {},
   "source": [
    "Need to add TF-IDF to the mix.\n",
    "\n",
    "notes from Carter \n",
    "\n",
    "  ('title', TfidfVectorizer(max_features = 6000, stop_words = 'english', ngram_range=(1,1)), 'title'),\n",
    "     ('content', TfidfVectorizer(max_features = 6000, stop_words = 'english', ngram_range=(1,1)), 'content')], n_jobs=3, verbose=True)\n",
    "     \n",
    "     https://github.com/georgetown-analytics/From-Russia-With-Love-fake-news-/blob/mast[]tep_4_feature_vectorization_and_model_evaluation_nodomain.ipynb\n",
    "     \n",
    "     https://www.scikit-yb.org/en/latest/api/text/index.html\n",
    "\n",
    "#sklearn text feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24463fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is the problem.\n",
    "\n",
    "def visualize_model(X, y, estimator,label_lst, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        #('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(\n",
    "        model, classes=label_lst,\n",
    "        cmap=\"YlGn\", size=(600, 360), **kwargs\n",
    "    )\n",
    "    visualizer.fit(X, y)\n",
    "    visualizer.score(X, y)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a415f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_visualize_model(X, y, estimator,label_lst, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        #('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    #Create the train and test data\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "    \n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(\n",
    "        model, classes=label_lst,\n",
    "        cmap=\"YlGn\", size=(600, 360), **kwargs\n",
    "    )\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(X,y,estimator,label_lst):\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    model = Pipeline([\n",
    "    (\"columns\", ColumnTransformer([\n",
    "        #('onehot', OneHotEncoder(), categorical),\n",
    "        ('scalar', RobustScaler(), numeric),\n",
    "        ('scalar2', RobustScaler(), numeric2),\n",
    "    ], remainder='drop')),\n",
    "        (\"imputer\",SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "\n",
    "    #Create the train and test data\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "    # Instantiate the visualizer with the classification model\n",
    "    confusion_matrix(\n",
    "        model,\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        classes=label_lst\n",
    "    )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it.\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        score_model(X, y, model)\n",
    "        visualize_model(X, y, model,cat_labels)\n",
    "        a_visualize_model(X, y, model,cat_labels)\n",
    "        conf_matrix(X, y, model,cat_labels)\n",
    "    except Exception as exc:\n",
    "        print(model, \n",
    "              traceback.format_exc(), \n",
    "              exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
